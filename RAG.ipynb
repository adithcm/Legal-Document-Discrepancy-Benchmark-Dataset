{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c57e75-3ce1-4a68-be8a-5b914153dd91",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.32.1)\n",
      "Requirement already satisfied: tqdm in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: torchvision in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.16.2)\n",
      "Requirement already satisfied: numpy in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: filelock in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
      "Requirement already satisfied: requests in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.2)\n",
      "Requirement already satisfied: click in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for torch>=1.6.0 from https://files.pythonhosted.org/packages/1e/86/477ec85bf1f122931f00a2f3889ed9322c091497415a563291ffc119dacc/torch-2.1.2-cp311-none-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached torch-2.1.2-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Using cached torch-2.1.2-cp311-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.1\n",
      "    Uninstalling torch-2.4.1:\n",
      "      Successfully uninstalled torch-2.4.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.4.1 requires torch==2.4.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11d17979-5540-48fb-b744-238a100c8105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import fitz\n",
    "import difflib\n",
    "import re\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3635c47-7c40-4798-a487-fde9efa33e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDn3S7Ltgw_ABPmw6cfD_qMv7PN8KXSlwA\"\n",
    "# 1. AIzaSyCVjSqp_8WwJMVaIi3dVSQDRic5I1869kE\n",
    "# 2. AIzaSyCKtZRj1pJMu1JVO7siNYcqG15oTgPSj3k\n",
    "# 3. AIzaSyAjby-dj9aBsolOdTDpvU7_x5uje8l4yiQ\n",
    "# 4. AIzaSyAGHtD2RAI1geToBsVjk-mIzVeuhlZQtA4 (Noel_)\n",
    "# 5. AIzaSyBTYgTD42xCABfJy1jsHchkZEhFaw8X1_c (Mannan_)\n",
    "# 7. AIzaSyDgafwAgDi2Zjvu6jdt_SIZ60VgK1Na32E (adi)\n",
    "# 8. AIzaSyCWI7QJXWYBGGWGdL37W8ll0sDIwz0zqlo(adi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c4dc80-1936-460d-b6e3-9197107e9465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Initialize the Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cd3d02-fc8a-4aa3-87e7-ae4dbac44afb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, imagine regular computers are like light switches: they can be either **on** (representing 1) or **off** (representing 0).  This is called a \"bit.\"\n",
      "\n",
      "Quantum computers are different. Instead of light switches, they're like **dimmer switches**. They can be both on and off *at the same time*, kind of a \"maybe\" state.  This \"maybe\" state is called a **qubit**.\n",
      "\n",
      "Here's the breakdown:\n",
      "\n",
      "*   **Bits (Regular Computers):** 0 or 1. Definite. Like flipping a coin and it lands on heads or tails.\n",
      "\n",
      "*   **Qubits (Quantum Computers):** Can be 0, 1, or *both* 0 and 1 **simultaneously**. This is called **superposition**.  Imagine the coin spinning in the air, it's *both* heads and tails at the same time until it lands.\n",
      "\n",
      "**Why is this important?**\n",
      "\n",
      "This \"both at once\" ability allows quantum computers to explore many possibilities at the same time. Think of trying to find your way out of a maze. A regular computer would try one path, then another, and another, until it finds the right one. A quantum computer can explore *all paths simultaneously* and find the solution much faster.\n",
      "\n",
      "**Another key concept is entanglement:**\n",
      "\n",
      "*   **Entanglement:** Imagine two of our spinning coins that are linked together.  When you flip one and it lands on heads, you *instantly* know the other one landed on tails (even if they're far apart). Entangled qubits are linked in a similar way.  This connection allows them to work together to solve complex problems.\n",
      "\n",
      "**In summary:**\n",
      "\n",
      "Quantum computers use qubits, which can be in a state of \"both 0 and 1 at the same time\" (superposition) and can be linked together in a special way (entanglement).  This allows them to:\n",
      "\n",
      "*   Explore many solutions simultaneously.\n",
      "*   Potentially solve problems that are too complex for regular computers.\n",
      "*   Perform certain calculations much, much faster.\n",
      "\n",
      "**What are they used for?**\n",
      "\n",
      "*   **Drug discovery and materials science:** Simulating molecules to create new medicines and materials.\n",
      "*   **Optimization problems:**  Finding the best solutions for things like logistics, finance, and scheduling.\n",
      "*   **Cryptography:**  Developing new ways to encrypt data (and potentially breaking existing encryption methods).\n",
      "*   **Artificial Intelligence:**  Training AI models more efficiently.\n",
      "\n",
      "**Important Note:** Quantum computing is still in its early stages of development. Building and programming quantum computers is very difficult, and they are not yet practical for all tasks. However, they hold enormous potential for the future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "response = model.generate_content(\"Explain quantum computing in simple terms.\")\n",
    "\n",
    "# Print the response\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c97f4d1b-0381-4ba9-83e2-3bbf2c4bb1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the MiniLM embedding model from Hugging Face\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f6d0822-8d46-4b15-8e1a-098de24d7d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Example input: LLM-generated \"contradicted\" law statement\n",
    "llm_generated_law = \"According to Section 18 of the Federal Privacy Act, data must be deleted after 6 months.\"\n",
    "\n",
    "# 2. Example real laws in your database (you can load these from a file or dataset)\n",
    "real_laws = [\n",
    "    \"Under Section 18 of the Federal Privacy Act, users must be notified before data deletion.\",\n",
    "    \"According to the Fair Credit Reporting Act, individuals have a right to dispute errors.\",\n",
    "    \"The California Consumer Privacy Act requires companies to delete user data upon request.\",\n",
    "    \"Section 11 of the Data Privacy Act mandates data retention for at least one year.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029166f8-93ad-426c-a437-b42f9703c81b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LLM Generated Law:\n",
      "According to Section 18 of the Federal Privacy Act, data must be deleted after 6 months.\n",
      "\n",
      " Closest Real Law Match:\n",
      "Under Section 18 of the Federal Privacy Act, users must be notified before data deletion.\n",
      "\n",
      " Similarity Score: 0.7701\n",
      "\n",
      " Law may be hallucinated or does not closely match any known entry.\n"
     ]
    }
   ],
   "source": [
    "# 3. Encode both the LLM output and the real laws\n",
    "llm_embedding = model.encode([llm_generated_law])\n",
    "real_law_embeddings = model.encode(real_laws)\n",
    "\n",
    "# 4. Compute cosine similarities\n",
    "similarities = cosine_similarity(llm_embedding, real_law_embeddings)[0]\n",
    "\n",
    "# 5. Get top match\n",
    "best_match_idx = np.argmax(similarities)\n",
    "best_match = real_laws[best_match_idx]\n",
    "confidence = similarities[best_match_idx]\n",
    "\n",
    "# 6. Display result\n",
    "print(\" LLM Generated Law:\")\n",
    "print(llm_generated_law)\n",
    "print(\"\\n Closest Real Law Match:\")\n",
    "print(best_match)\n",
    "print(f\"\\n Similarity Score: {confidence:.4f}\")\n",
    "\n",
    "# Optional: Threshold-based judgment\n",
    "if confidence > 0.8:\n",
    "    print(\"\\n Law is likely real or referenced correctly.\")\n",
    "else:\n",
    "    print(\"\\n Law may be hallucinated or does not closely match any known entry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89f40d-1dda-4837-8f4d-9cb0a8fe1ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
