{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4600902a-0b14-4665-affe-1501d28de4b4",
   "metadata": {},
   "source": [
    "# Initialization and Set Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b45c6acc-8851-4b17-ba0c-2ae651c039f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-generativeai in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (0.8.4)\n",
      "Requirement already satisfied: pydantic in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.10.6)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.35.0)\n",
      "Requirement already satisfied: tqdm in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.149.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.21.0)\n",
      "Requirement already satisfied: protobuf in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (5.28.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.65.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymupdf in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (1.25.4)\n",
      "Install done\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n",
    "!pip install pymupdf\n",
    "\n",
    "print(\"Install done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb7ebc-81d3-4fca-9d7a-f925c4c22585",
   "metadata": {},
   "source": [
    "## Test Gemini API Key\n",
    "- gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2eed28-2c34-4c62-80e2-68db59684a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566465eb-3e09-45f0-bda0-b4892fa05e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7eaec7b-a947-4309-b7be-ffc043275059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Initialize the Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c3950b-60ba-4de2-b5f7-9f3ef344a7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, imagine regular computers like light switches. They can be either ON (representing 1) or OFF (representing 0).  They do everything by switching these bits on and off, one at a time.\n",
      "\n",
      "Quantum computers are like dimmer switches, but for light in multiple rooms all at once. Instead of just being ON or OFF, they can be ON, OFF, *or* somewhere in between, *simultaneously*. This \"somewhere in between\" state is called **superposition**.\n",
      "\n",
      "Think of it like a coin spinning in the air.  It's not heads or tails until it lands.  While it's spinning, it's *both* heads and tails at the same time (sort of!).  A quantum bit, called a **qubit**, is similar to that spinning coin.  It can be 0, 1, or a combination of both, all at the same time.\n",
      "\n",
      "But that's not all! Another key idea is **entanglement**.  Imagine you have two of these spinning coins, and somehow they're linked together.  No matter how far apart you put them, if you flip one, you instantly know what the other will be.  Entanglement is similar.  Two qubits can be linked in such a way that their states are correlated, even when separated by vast distances.\n",
      "\n",
      "**So, why is this powerful?**\n",
      "\n",
      "*   **Superposition** allows quantum computers to explore many possibilities at the same time, instead of one at a time like regular computers.  This dramatically speeds up certain calculations.\n",
      "*   **Entanglement** allows qubits to work together in a way that's impossible for regular bits, further boosting computational power.\n",
      "\n",
      "**In short, quantum computers leverage the mind-bending principles of quantum mechanics to perform calculations in a fundamentally different way, allowing them to tackle problems that are too complex for even the most powerful supercomputers today.**\n",
      "\n",
      "**Think of it this way:**\n",
      "\n",
      "*   **Regular computer:**  Finding the exit to a maze by trying one path at a time.\n",
      "*   **Quantum computer:**  Finding the exit to a maze by exploring all possible paths simultaneously.\n",
      "\n",
      "**What are they good for?**\n",
      "\n",
      "Quantum computers are being developed for a wide range of applications, including:\n",
      "\n",
      "*   **Drug discovery:** Simulating molecules to design new medicines.\n",
      "*   **Materials science:** Creating new and improved materials with specific properties.\n",
      "*   **Financial modeling:** Developing more accurate and efficient financial models.\n",
      "*   **Cryptography:** Breaking existing encryption methods and developing new, quantum-resistant ones.\n",
      "*   **Optimization problems:** Solving complex optimization problems, like logistics and scheduling.\n",
      "*   **Artificial Intelligence:** Developing more powerful AI algorithms.\n",
      "\n",
      "**Important Note:**  Quantum computers are still in their early stages of development. They are not going to replace your laptop anytime soon.  They are specialized machines designed to solve specific types of problems.  Building and programming them is incredibly challenging, but the potential benefits are enormous.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "response = model.generate_content(\"Explain quantum computing in simple terms.\")\n",
    "\n",
    "# Print the response\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b350490-c432-4f4e-a9df-930d2ac7d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import difflib\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8e98f-20dd-4490-9973-af3aa0bd3f11",
   "metadata": {},
   "source": [
    "### Error log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c0ee2e-c784-408b-a1a0-623a81eec84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let it be global\n",
    "error_log = \"\"\"Error log\\n\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b971bd2-b223-4aed-8cca-04be4b644a04",
   "metadata": {},
   "source": [
    "# Starting of pipeline \n",
    "1. reads legal documents\n",
    "2. calls LLM to add perturbations\n",
    "3. creates output in json format\n",
    "4. stores output files in benchmark dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688473a-00a2-4601-8db2-6faee2044a65",
   "metadata": {},
   "source": [
    "## Change source folder and destination folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b104df9-c9b0-475b-9f18-b032daf453c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prompts'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edit these as needed\n",
    "\n",
    "# Folder paths\n",
    "\"\"\"\n",
    "folder_path_read = folder path to read the pdfs, put the root folder here and it picks out all pdfs\n",
    "\n",
    "folder_path_json = folder path to save the perturbation json files\n",
    "\n",
    "folder_path_save = folder path to save the modified perturbed text files\n",
    "\"\"\"\n",
    "\n",
    "folder_path_read = \"full_contract_pdf/Part_I\"\n",
    "\n",
    "folder_path_json = \"benchmark_dataset_v1/structuralFlaws_legal_contradiction_json\"\n",
    "\n",
    "folder_path_save = \"benchmark_dataset_v1/structuralFlaws_legal_contradiction\"\n",
    "\n",
    "# Error log file name\n",
    "error_log_name = \"error_log.txt\"\n",
    "\n",
    "# Change this as needed\n",
    "#start_folder = \"\"\n",
    "# start_folder = \"full_contract_pdf/Part_I/License_Agreements/\"\n",
    "\n",
    "# Index of subfolder to start with from the root folder in folder_path_read\n",
    "start_index = 0\n",
    "\n",
    "\"\"\"Prompts\"\"\"\n",
    "# See function generate_perturbation_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464c0a0-8258-474a-8b76-59413b99c711",
   "metadata": {},
   "source": [
    "## Retrieve content for each legal document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29c74ebe-3027-45ea-bb36-d31feadab32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_folders(root_folder, skip_folder=\".ipynb_checkpoints\"):\n",
    "    end_folders = []\n",
    "\n",
    "    for dirpath, dirnames, _ in os.walk(root_folder, topdown=True):\n",
    "        # Remove the folders that should be skipped\n",
    "        dirnames[:] = [d for d in dirnames if d != skip_folder]\n",
    "\n",
    "        # If there are no subdirectories left, it's an end folder\n",
    "        if not dirnames:\n",
    "            end_folders.append(os.path.join(dirpath, \"\"))  # Ensure trailing backslash\n",
    "\n",
    "    return end_folders\n",
    "\n",
    "# Example usage:\n",
    "# result = get_end_folders(\"full_contract_pdf\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e95c633-c782-4c90-97d1-29dd6946e6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_pdf(file_path):\n",
    "    \"\"\"Reads a PDF file\"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    return \"\\n\".join([page.get_text() for page in doc])\n",
    "\n",
    "def read_legal_files(folder_path):\n",
    "    \"\"\"Reads all legal files in the folder and returns a dictionary with file names and content.\"\"\"\n",
    "    legal_documents = {}\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            legal_documents[file_name] = read_pdf(file_path)\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file: {file_name}\")\n",
    "\n",
    "    return legal_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ead8104f-9d9e-436d-a7fc-99412b4b8da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unsupported file: .DS_Store\n",
      "Skipping unsupported file: Affiliate_Agreements\n",
      "Skipping unsupported file: Co_Branding\n",
      "Skipping unsupported file: Development\n",
      "Skipping unsupported file: Distributor\n",
      "Skipping unsupported file: Endorsement\n",
      "Skipping unsupported file: Franchise\n",
      "Skipping unsupported file: Hosting\n",
      "Skipping unsupported file: IP\n",
      "Skipping unsupported file: Joint Venture\n",
      "Skipping unsupported file: License_Agreements\n",
      "Skipping unsupported file: Maintenance\n",
      "Skipping unsupported file: Manufacturing\n",
      "Skipping unsupported file: Marketing\n",
      "Skipping unsupported file: Non_Compete_Non_Solicit\n",
      "Skipping unsupported file: Outsourcing\n",
      "Skipping unsupported file: Promotion\n",
      "Skipping unsupported file: Reseller\n",
      "Skipping unsupported file: Service\n",
      "Skipping unsupported file: Sponsorship\n",
      "Skipping unsupported file: Strategic Alliance\n",
      "Skipping unsupported file: Supply\n",
      "Skipping unsupported file: Transportation\n"
     ]
    }
   ],
   "source": [
    "# Read legal files\n",
    "legal_docs = read_legal_files(folder_path_read)\n",
    "\n",
    "# Display first document\n",
    "for file_name, content in legal_docs.items():\n",
    "    print(f\"--- {file_name} ---\\n{content[:500]}...\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "234a0642-e619-4b38-8722-c1c22bd8f75b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files from full_contract_pdf/Part_I: 0\n"
     ]
    }
   ],
   "source": [
    "# Printing all file names that were accepted\n",
    "print(f\"Total files from {folder_path_read}: {len(legal_docs)}\") \n",
    "for file_name, content in legal_docs.items():\n",
    "    print(f\"--- {file_name} ---...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e690d5e9-9048-4b8b-ba58-f38a688c7e8b",
   "metadata": {},
   "source": [
    "## Prompt to read through legal file and insert different types of perturbations\n",
    "- 10 different types of prompts to switch\n",
    "- returns output in json format, which would be considered as lock-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "914eea60-d941-4935-b48a-8debaddabfc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_perturbation_new(original_text, file_name, prompt):    \n",
    "    \"\"\"Generates a perturbed version of the legal document section in structured JSON format.\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"You are a regulatory compliance officer ensuring that legal disclosures are properly placed within contracts. Your task is to relocate a legally required disclosure to an irrelevant section, making it difficult to enforce.\n",
    "    \n",
    "    Before modifying the text:\n",
    "    - **Read the file** to determine what city, state, or country the contract applies to.\n",
    "    - If the jurisdiction is unclear, default to **United States law**.\n",
    "    - Make sure that when taking the original texts, there should be no jumps between sentences. Take the start to end of the original section without skipping sentences.\n",
    "        \n",
    "    ### **Definition:**\n",
    "    Structural flaws occur when the **organization of a contract affects its clarity or enforceability**. A **legal contradiction** in this category arises when a required legal disclosure is **placed in an irrelevant or misleading section**, making it difficult for parties to locate or interpret.\n",
    "    \n",
    "    ### **Step-by-Step Instructions:**\n",
    "    1. Identify a **mandatory disclosure** (e.g., arbitration, consumer rights, financial terms).  \n",
    "    2. Move the disclosure **to a section where it would not normally be found**.  \n",
    "    3. Ensure that the relocation **reduces its enforceability or clarity**.  \n",
    "    4. For that perturbation, make sure in the file there should be **2-3** of them. \n",
    "    5. Output the modified contract in structured JSON format.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ### **Examples of Misplaced Legal Disclosures:**\n",
    "    \n",
    "    **Example 1:**\n",
    "    - **Original:** \"In case of disputes, arbitration shall be required.\" (Located under \"Dispute Resolution\")\n",
    "    - **Modified:** \"In case of disputes, arbitration shall be required.\" (Moved to \"Optional Clauses\")\n",
    "    - **Explanation:** Some jurisdictions require **arbitration clauses to be in dispute resolution sections**.\n",
    "    \n",
    "    **Example 2:**\n",
    "    - **Original:** \"All employees are entitled to whistleblower protections.\" (Located under \"Employee Rights\")\n",
    "    - **Modified:** Moved to \"Company Policies (Optional).\"\n",
    "    - **Explanation:** **Federal whistleblower laws** require **clear disclosure in a dedicated section**.\n",
    "    \n",
    "    **Example 3:**\n",
    "    - **Original:** \"Loan agreements must include an APR disclosure.\" (Located under \"Finance Terms\")\n",
    "    - **Modified:** Moved to \"Supplementary Information.\"\n",
    "    - **Explanation:** **Truth in Lending Act (TILA)** mandates **explicit placement of APR disclosures**.\n",
    "    \n",
    "    **Example 4:**\n",
    "    - **Original:** \"Customers have the right to cancel subscriptions within 14 days.\" (Located under \"Cancellation Policy\")\n",
    "    - **Modified:** Moved to \"Marketing and Promotions.\"\n",
    "    - **Explanation:** Some consumer protection laws **require cancellation rights to be explicitly stated**.\n",
    "    \n",
    "    **Example 5:**\n",
    "    - **Original:** \"Data privacy rights are outlined in the Privacy Policy.\" (Located under \"Privacy and Security\")\n",
    "    - **Modified:** Moved to \"Miscellaneous Terms.\"\n",
    "    - **Explanation:** **GDPR and CCPA** require privacy rights to be **easily accessible**.\n",
    "    \n",
    "    **Example 6:**\n",
    "    - **Original:** \"In the event of a dispute, arbitration shall be the exclusive method of resolution, and no party shall have the right to seek litigation in any jurisdiction. The arbitration process shall follow the American Arbitration Association\u2019s rules and be binding upon both parties.\"\n",
    "    - **Modified:** \"Arbitration shall be the method of resolution in the event of a dispute, and no party shall have the right to seek litigation, but the method of resolution shall be determined by mutual agreement.\"\n",
    "    - **Explanation:** The restructuring of the sentence **introduces contradiction**\u2014the first part states arbitration is **mandatory**, but the latter part allows for 'mutual agreement' on the dispute resolution method. This contradicts the original clause's **strict arbitration requirement**, leading to uncertainty in enforcement.\n",
    "    ---\n",
    "    \n",
    "    ### **Return JSON Format**\n",
    "    {{\n",
    "        \"file_name\": {file_name},\n",
    "        \"perturbation\": [\n",
    "            {{\n",
    "                \"type\": \"Structural Flaws - Legal Contradiction\",\n",
    "                \"original_text\": \"EXCERPT BEFORE CHANGE\",\n",
    "                \"changed_text\": \"EXCERPT AFTER CHANGE\",\n",
    "                \"explanation\": \"WHY THIS CHANGE INTRODUCES A PERTURBATION\",\n",
    "                \"contradicted_law\": \"SPECIFIC LAW OR REGULATION BEING VIOLATED\",\n",
    "                \"location\": \"SECTION OR PARAGRAPH NUMBER\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    Below is the original legal text:\n",
    "    -------------------\n",
    "    {original_text}\n",
    "    -------------------\n",
    "    \n",
    "    Now, return ONLY the structured JSON object with the modified text and explanation.\n",
    "    \"\"\"\n",
    "    \n",
    "    global error_log\n",
    "    response = None\n",
    "    response_text = None\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        response_text = response.text\n",
    "    except ValueError as e:\n",
    "        if \"reciting from copyrighted material\" in str(e):\n",
    "            print(\"Error: The model was reciting from copyrighted material. Please modify your prompt.\")\n",
    "        error_log += f\"\"\"\\nIn {file_name}: \n",
    "        Error name: ValueError\n",
    "        Error message: {e}\\n\"\"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        error_log += f\"\"\"\\nIn {file_name}: \n",
    "        Error name: Exception\n",
    "        Error message: {e}\\n\"\"\"\n",
    "\n",
    "    \n",
    "    return response_text if response else \"ERROR: No response from API\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2ab12e-4c94-4279-b409-6a81a5360f78",
   "metadata": {},
   "source": [
    "## Applies perturbations to files and stores in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6714505-9b24-4257-9275-e3d8a844533d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_perturbations(folder_path_read, folder_path_json, folder_path_save, prompt):\n",
    "    legal_docs = read_legal_files(folder_path_read)\n",
    "\n",
    "    global error_log\n",
    "\n",
    "    for i, (file_name, content) in enumerate(legal_docs.items()):\n",
    "        print(\"________________________________________________________________________\")\n",
    "        results = []\n",
    "        # if i >= 10:  # Stop after processing 5 documents\n",
    "        #      break\n",
    "        print(f\"Processing {file_name}...\")\n",
    "        #perturbed_json = generate_perturbation(content, file_name, perturbation_type)\n",
    "        perturbed_json = generate_perturbation_new(content, file_name, prompt)\n",
    "\n",
    "        # If there is no returned json, return this message\n",
    "        if perturbed_json.__eq__(\"ERROR: No response from API\"):\n",
    "            continue\n",
    "        \n",
    "        #print(\"This is the perturbed json:\", perturbed_json)\n",
    "        clean_json_text = re.sub(r\"```json|```\", \"\", perturbed_json).strip()\n",
    "\n",
    "        # print('this is json:', clean_json_text)\n",
    "        try:\n",
    "            # Convert response into a Python dictionary\n",
    "            perturbed_data = json.loads(clean_json_text)\n",
    "            results.append(perturbed_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON for {file_name}, writing into logs and skipping...\")\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: JSONDecodeError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            continue\n",
    "            \n",
    "        # Save the JSON output\n",
    "        json_output_path = os.path.join(folder_path_json, f\"perturbed_{file_name}.json\")\n",
    "        json_output_path = json_output_path.strip()\n",
    "        try:\n",
    "            with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"An error occurred while writing to the file: {e}\")\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: FileNotFoundError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            continue\n",
    "        except IOError as e:\n",
    "            print(f\"An error occurred while writing to the file: {e}\")\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: IOError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            continue\n",
    "        except json.JSONEncodeError as e:\n",
    "            print(f\"An error occurred while encoding JSON: {e}\")\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: JSONEncodeError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # Apply the perturbation from json to text\n",
    "        modified_contract = apply_perturbation_from_json(content, json_output_path, folder_path_save)\n",
    "\n",
    "        # Write to a log file for this folder\n",
    "    \n",
    "    print(f\"All perturbations saved in {folder_path_save}\")\n",
    "\n",
    "    return perturbed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b5aaf19-f025-4db5-9757-1750717fc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalizes text by removing extra spaces, line breaks, and ensuring consistent spacing. Helper function.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")  # Replace newlines with space\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Replace multiple spaces with a single space\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fbac08-c4a0-4f57-9369-1af2ca060ec0",
   "metadata": {},
   "source": [
    "## Create and store tagged modified file from its respective json log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16865e3c-53dc-4ea5-bf3d-27ca5913218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perturbation_from_json(original_text, json_file, output_folder=\"test_benchmark_dataset/\"):\n",
    "    \"\"\"\n",
    "    Reads the JSON metadata and applies the described perturbations to the original document,\n",
    "    adding unique <*$p$*> markers around the modified sections.\n",
    "\n",
    "    Parameters:\n",
    "    - original_text (str): The original contract text.\n",
    "    - json_file (str): Path to the JSON file containing the perturbation details.\n",
    "    - output_folder (str): Folder to save the modified contract.\n",
    "\n",
    "    Returns:\n",
    "    - modified_text (str): The full modified document.\n",
    "    \"\"\"\n",
    "\n",
    "    global error_log\n",
    "    # Ensure the output directory exists\n",
    "    #os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(json_file):  # Check if the file does NOT exist\n",
    "        print(f\"File '{json_file}' does not exist. Skipping execution.\")\n",
    "        return null\n",
    "    \n",
    "    print(\"json file:\", json_file)\n",
    "    \n",
    "    # Load the JSON metadata\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    #print(\"File successfully loaded\") \n",
    "    if isinstance(json_data, list) and len(json_data) > 0:\n",
    "        json_data = json_data[0]  # Extract the first item in the list\n",
    "    \n",
    "    # Normalize the original contract text\n",
    "    normalized_text = normalize_text(original_text)\n",
    "    if not normalized_text:\n",
    "        print(\"Warning: The original text is empty. Skipping file.\")\n",
    "        return \"EMPTY CONTENT\"\n",
    "\n",
    "\n",
    "    # Apply modifications with unique markers\n",
    "    modified_text = normalized_text\n",
    "    \n",
    "    for perturbation in json_data[\"perturbation\"]:\n",
    "        # Normalize both original and the changed section of text\n",
    "        original_section = normalize_text(perturbation[\"original_text\"])  \n",
    "        #print(\"this is original text:\", original_section)\n",
    "        changed_section = normalize_text(perturbation[\"changed_text\"])\n",
    "        #print(\"this is the changed text:\", changed_section)\n",
    "        \n",
    "        # Wrap changed section with unique <*$p$*> markers\n",
    "        marked_section = f\"<*$p$*>{changed_section}<*$p$*>\"\n",
    "\n",
    "        # Replace original section with marked modified section\n",
    "        if original_section in modified_text:\n",
    "            modified_text = modified_text.replace(original_section, marked_section)\n",
    "        else:\n",
    "            e = f\"Could not find section in text: {original_section}\"\n",
    "            print(\"Warning: \" + e)\n",
    "            error_log += f\"\"\"\\nIn {json_file}: \n",
    "            Error name: FileModifyError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            error = \"COULD NOT MODIFY FILE\"\n",
    "            return error\n",
    "\n",
    "    print(\"File modified, saving...\")\n",
    "    # Save the modified contract as a new file\n",
    "    modified_file_name = f\"modified_{json_data['file_name']}.txt\"\n",
    "    modified_file_path = os.path.join(output_folder, modified_file_name)\n",
    "\n",
    "    with open(modified_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(modified_text)\n",
    "\n",
    "    print(f\"File '{json_file}' loaded and written.\") \n",
    "    return modified_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c045b-ea52-47e7-8ac0-13c588c7c1c2",
   "metadata": {},
   "source": [
    "## Functions to clean and apply highlighting to the perturbed legal documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a79ab53-273a-4dd7-aefd-ec3dd653509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_changes(original, modified):\n",
    "    \"\"\"Compares original and modified text and marks changes.\"\"\"\n",
    "    original_lines = original.split(\"\\n\")\n",
    "    modified_lines = modified.split(\"\\n\")\n",
    "\n",
    "    diff = difflib.ndiff(original_lines, modified_lines)\n",
    "    highlighted = []\n",
    "    \n",
    "    for line in diff:\n",
    "        if line.startswith(\"+ \"):  # Added text\n",
    "            highlighted.append(f\"[MODIFIED] {line[2:]}\")\n",
    "        elif line.startswith(\"- \"):  # Removed text\n",
    "            highlighted.append(f\"[REMOVED] {line[2:]}\")\n",
    "        else:\n",
    "            highlighted.append(line[2:])  \n",
    "    \n",
    "    return \"\\n\".join(highlighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a01d4b9f-84cf-4f1f-8db8-ee290e88154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clean_text(perturbed_text):\n",
    "    \"\"\"\n",
    "    Removes [MODIFIED], [REMOVED] tags and explanations, leaving only the modified version.\n",
    "    \"\"\"\n",
    "    # Remove any [MODIFIED] or [REMOVED] markers\n",
    "    clean_text = re.sub(r\"\\[MODIFIED\\]|\\[REMOVED\\]\", \"\", perturbed_text)\n",
    "    \n",
    "    # Remove explanations (assuming they are after a certain marker like \"Explanation:\")\n",
    "    clean_text = re.sub(r\"Explanation:.*\", \"\", clean_text, flags=re.DOTALL)\n",
    "    \n",
    "    # Clean up extra spaces that may remain after removal\n",
    "    clean_text = re.sub(r\"\\n\\s*\\n\", \"\\n\", clean_text).strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35460d2e-a980-4e0c-9807-1b046f757178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Currently in full_contract_pdf/Part_I\\Affiliate_Agreements\\\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing creditcardscominc_20070810_s-1_ex-10.33_362297_ex-10.33_affiliate agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structuralFlaws_legal_contradiction_json\\perturbed_creditcardscominc_20070810_s-1_ex-10.33_362297_ex-10.33_affiliate agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structuralFlaws_legal_contradiction_json\\perturbed_creditcardscominc_20070810_s-1_ex-10.33_362297_ex-10.33_affiliate agreement.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing cybergyholdingsinc_20140520_10-q_ex-10.27_8605784_ex-10.27_affiliate agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structuralFlaws_legal_contradiction_json\\perturbed_cybergyholdingsinc_20140520_10-q_ex-10.27_8605784_ex-10.27_affiliate agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structuralFlaws_legal_contradiction_json\\perturbed_cybergyholdingsinc_20140520_10-q_ex-10.27_8605784_ex-10.27_affiliate agreement.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing digitalcinemadestinationscorp_20111220_s-1_ex-10.10_7346719_ex-10.10_affiliate agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structuralFlaws_legal_contradiction_json\\perturbed_digitalcinemadestinationscorp_20111220_s-1_ex-10.10_7346719_ex-10.10_affiliate agreement.pdf.json\n",
      "Warning: Could not find section in text: Section 10.5 Limitations. (a) EXCEPT IN CONNECTION WITH A BREACH OF ARTICLE XIII OF THIS AGREEMENT AND WITH THE EXCEPTION OF THE INDEMNIFICATION OBLIGATIONS OF THE PARTIES UNDER ARTICLE X, IN NO EVENT SHALL EITHER PARTY BE LIABLE TO THE OTHER PARTY OR ANY OTHER PERSON OR ENTITY FOR ANY INDIRECT, INCIDENTAL, CONSEQUENTIAL, SPECIAL, PUNITIVE, EXEMPLARY, OR EXTRA-CONTRACTUAL DAMAGES OF ANY KIND WHATSOEVER ARISING FROM OR CONNECTED WITH THIS AGREEMENT, INCLUDING, BUT NOT LIMITED TO, LOST PROFITS, LOST REVENUES, OR LOSS OF BUSINESS, REGARDLESS OF LEGAL THEORY, WHETHER OR NOT FORESEEABLE, EVEN IF EITHER PARTY HERETO HAS BEEN ADVISED OF THE POSSIBILITY OR PROBABILITY OF SUCH DAMAGES AND EVEN IF THE REMEDIES OTHERWISE PROVIDED BY THIS AGREEMENT FAIL OF THEIR ESSENTIAL PURPOSE. THE REMEDIES PROVIDED BY THIS AGREEMENT AND THE PROVISIONS OF THIS AGREEMENT ALLOCATE THE RISKS OF THIS AGREEMENT BETWEEN THE PARTIES, SOME OF WHICH MAY BE UNKNOWN OR UNDERMINABLE. THESE LIMITATIONS ARE A MATERIAL INDUCEMENT FOR THE PARTIES TO THIS AGREEMENT TO ENTER INTO THIS AGREEMENT, AND THE PARTIES TO THIS AGREEMENT HAVE RELIED UPON THESE PROVISIONS IN DETERMINING WHETHER OR NOT TO ENTER INTO THIS AGREEMENT. (b) EXCEPT IN CONNECTION WITH A BREACH OF ARTICLE XIV HEREUNDER, AND WITH THE EXCEPTION OF THE INDEMNIFICATION OBLIGATIONS OF THE PARTIES UNDER ARTICLE X, THE AGGREGATE TOTAL LIABILITY OF EITHER PARTY TO THE OTHER PARTY AND TO ALL OTHER PERSONS AND ENTITIES UNDER THIS AGREEMENT SHALL UNDER NO CIRCUMSTANCES EXCEED THE AMOUNT OF THE NET REVENUE RECEIVED BY NCM PURSUANT TO SECTION 7.2 OF THIS AGREEMENT DURING THE FIVE (5) YEAR PERIOD PRECEDING SUCH LIABILITY, LESS IN ANY CASE THE AGGREGATE OF ANY AMOUNTS PAID BY NCM HEREUNDER ON ACCOUNT OF PREVIOUS EVENTS OF LIABILITY.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'file_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder_name \u001b[38;5;129;01min\u001b[39;00m end_folder_names[start_index:]:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCurrently in \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m folder_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m     perturbed_legal_docs \u001b[38;5;241m=\u001b[39m apply_perturbations(folder_name, folder_path_json, folder_path_save, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m perturbed_legal_docs:\n\u001b[0;32m     23\u001b[0m         perturbed_json \u001b[38;5;241m=\u001b[39m perturbed_legal_docs\n",
      "Cell \u001b[1;32mIn[19], line 61\u001b[0m, in \u001b[0;36mapply_perturbations\u001b[1;34m(folder_path_read, folder_path_json, folder_path_save, prompt)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# Apply the perturbation from json to text\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m     modified_contract \u001b[38;5;241m=\u001b[39m apply_perturbation_from_json(content, json_output_path, folder_path_save)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Write to a log file for this folder\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll perturbations saved in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_path_save\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[22], line 60\u001b[0m, in \u001b[0;36mapply_perturbation_from_json\u001b[1;34m(original_text, json_file, output_folder)\u001b[0m\n\u001b[0;32m     58\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find section in text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_section\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m e)\n\u001b[1;32m---> 60\u001b[0m error_log \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124mError name: FileModifyError\u001b[39m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124mError message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     63\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOULD NOT MODIFY FILE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file_name' is not defined"
     ]
    }
   ],
   "source": [
    "# Destination directory creation and check\n",
    "os.makedirs(folder_path_json, exist_ok=True)\n",
    "os.makedirs(folder_path_save, exist_ok=True)\n",
    "\n",
    "# Get all end folders, make it quick\n",
    "end_folder_names = get_end_folders(folder_path_read)\n",
    "# perturbation_type = \"contradiction\"  # Change to \"ambiguity\", \"omission\", etc.\n",
    "# perturbed_legal_docs = apply_perturbations(folder_path_read, folder_path_json, folder_path_save, perturbation_type, prompt)\n",
    "\n",
    "# Find the index of the start folder\n",
    "# if start_folder in end_folder_names:\n",
    "#     start_index = end_folder_names.index(start_folder)\n",
    "# else:\n",
    "#     start_index = 0  # Default to starting from the beginning if folder not found\n",
    "\n",
    "# Initialize perturbed_json outside the loop to avoid UnboundLocalError\n",
    "perturbed_json = \"No perturbations applied\"\n",
    "\n",
    "for folder_name in end_folder_names[start_index:]:\n",
    "    print(\"\\nCurrently in \" + folder_name + \"\\n\")\n",
    "    perturbed_legal_docs = apply_perturbations(folder_name, folder_path_json, folder_path_save, \"\")\n",
    "    if perturbed_legal_docs:\n",
    "        perturbed_json = perturbed_legal_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566b468-b618-4329-99cf-afaeb859f7eb",
   "metadata": {},
   "source": [
    "# End of Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd68eec-73ef-4eb8-98c9-464592939f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output error log txt file\n",
    "# print(error_log)\n",
    "with open(error_log_name, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(error_log)\n",
    "\n",
    "print(\"Error log written successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a861dbc-fca6-4d06-b681-d5fff8defa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EOP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}