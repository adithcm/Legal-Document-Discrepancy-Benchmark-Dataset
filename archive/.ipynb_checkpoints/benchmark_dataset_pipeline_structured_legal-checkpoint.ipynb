{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4600902a-0b14-4665-affe-1501d28de4b4",
   "metadata": {},
   "source": [
    "# Initialization and Set Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b45c6acc-8851-4b17-ba0c-2ae651c039f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-generativeai in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (0.8.4)\n",
      "Requirement already satisfied: google-api-core in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.21.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: protobuf in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (5.28.2)\n",
      "Requirement already satisfied: tqdm in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.149.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: pydantic in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.10.6)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.35.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.65.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymupdf in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (1.25.4)\n",
      "Install done\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n",
    "!pip install pymupdf\n",
    "\n",
    "print(\"Install done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb7ebc-81d3-4fca-9d7a-f925c4c22585",
   "metadata": {},
   "source": [
    "## Test Gemini API Key\n",
    "- gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf2eed28-2c34-4c62-80e2-68db59684a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "566465eb-3e09-45f0-bda0-b4892fa05e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7eaec7b-a947-4309-b7be-ffc043275059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Initialize the Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58c3950b-60ba-4de2-b5f7-9f3ef344a7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, imagine regular computers like light switches. They can only be either **on** (representing a 1) or **off** (representing a 0).  That's binary.\n",
      "\n",
      "Quantum computers are more like dimmer switches.  Instead of just being on or off, they can be **on, off, *or anywhere in between, all at the same time***.  This \"in-between\" state is called **superposition**.\n",
      "\n",
      "Think of it like this:\n",
      "\n",
      "* **Classical Bit (Light Switch):** Definitely ON or OFF.  Either a 1 or a 0.\n",
      "* **Quantum Bit (Qubit, Dimmer Switch):**  Can be ON, OFF, or *a combination of both* at the same time.  It's like a blurry mix of 1 and 0 until you look at it.\n",
      "\n",
      "This \"combination\" is where the power comes from.  Here's why:\n",
      "\n",
      "* **Superposition:**  A qubit can represent multiple possibilities simultaneously, allowing quantum computers to explore many potential solutions at once.  Imagine trying to find the best route in a maze. A classical computer tries each path one by one. A quantum computer, thanks to superposition, tries *all* paths at the same time.\n",
      "\n",
      "* **Entanglement:**  Imagine two of these \"dimmer switches\" linked in a weird way. If you change one, the other instantly changes to match (or become the opposite, depending on how they're linked), even if they're far apart.  This is **entanglement**.  It allows qubits to work together in a coordinated way, performing calculations in parallel and exponentially increasing the processing power.\n",
      "\n",
      "**So, in a nutshell:**\n",
      "\n",
      "Quantum computers use qubits that can be in multiple states at once (superposition) and are linked together in a strange way (entanglement) to explore many solutions simultaneously.  This allows them to solve certain types of problems much faster and more efficiently than classical computers.\n",
      "\n",
      "**Think of it like searching for a specific grain of sand on a beach:**\n",
      "\n",
      "* **Classical Computer:** You would painstakingly examine each grain of sand, one at a time.\n",
      "* **Quantum Computer:** You could somehow examine *all* the grains of sand at once, finding the specific one almost instantly.\n",
      "\n",
      "**What are quantum computers good for?**\n",
      "\n",
      "* **Drug discovery and materials science:** Simulating complex molecules to design new drugs and materials.\n",
      "* **Cryptography:** Breaking existing encryption and developing new, quantum-resistant encryption methods.\n",
      "* **Financial modeling:** Predicting market trends and managing risk more effectively.\n",
      "* **Optimization:** Finding the best solutions to complex problems, like optimizing supply chains or traffic flow.\n",
      "* **Artificial Intelligence:** Training AI models more efficiently and creating more powerful AI algorithms.\n",
      "\n",
      "**Important Note:** Quantum computers are *not* going to replace your laptop or phone anytime soon. They are specialized machines designed for specific types of problems that are too difficult for classical computers. They are still in the early stages of development, but they hold immense potential for the future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "response = model.generate_content(\"Explain quantum computing in simple terms.\")\n",
    "\n",
    "# Print the response\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2b350490-c432-4f4e-a9df-930d2ac7d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import difflib\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8e98f-20dd-4490-9973-af3aa0bd3f11",
   "metadata": {},
   "source": [
    "### Error log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20c0ee2e-c784-408b-a1a0-623a81eec84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let it be global\n",
    "error_log = \"\"\"Error log\\n\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b971bd2-b223-4aed-8cca-04be4b644a04",
   "metadata": {},
   "source": [
    "# Starting of pipeline \n",
    "1. reads legal documents\n",
    "2. calls LLM to add perturbations\n",
    "3. creates output in json format\n",
    "4. stores output files in benchmark dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688473a-00a2-4601-8db2-6faee2044a65",
   "metadata": {},
   "source": [
    "## Change source folder and destination folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b104df9-c9b0-475b-9f18-b032daf453c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prompts'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edit these as needed\n",
    "\n",
    "# Folder paths\n",
    "\"\"\"\n",
    "folder_path_read = folder path to read the pdfs, put the root folder here and it picks out all pdfs\n",
    "\n",
    "folder_path_json = folder path to save the perturbation json files\n",
    "\n",
    "folder_path_save = folder path to save the modified perturbed text files\n",
    "\"\"\"\n",
    "\n",
    "folder_path_read = \"full_contract_pdf/Part_I/\"\n",
    "\n",
    "folder_path_json = \"benchmark_dataset_v1/structural_legal_json/\"\n",
    "\n",
    "folder_path_save = \"benchmark_dataset_v1/structural_legal_contradication/\"\n",
    "\n",
    "# Error log file name\n",
    "error_log_name = \"error_log_misaligned_terminology_inText.txt\"\n",
    "\n",
    "# Change this as needed\n",
    "#start_folder = \"\"\n",
    "#start_folder = \"full_contract_pdf/Part_I/License_Agreements/\"\n",
    "\n",
    "# Index of subfolder to start with from the root folder in folder_path_read\n",
    "start_index = 0\n",
    "\n",
    "\"\"\"Prompts\"\"\"\n",
    "# See function generate_perturbation_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee1eaf",
   "metadata": {},
   "source": [
    "Mannan's Recursive Function Cause My Stuff Always Errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e84daa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_legal_files_recursive(root_folder):\n",
    "    \"\"\"\n",
    "    Recursively reads all PDF files under the given root folder and \n",
    "    returns a dictionary with keys as the full file paths and values as the file content.\n",
    "    \"\"\"\n",
    "    legal_documents = {}\n",
    "    for dirpath, _, filenames in os.walk(root_folder):\n",
    "        for file_name in filenames:\n",
    "            if file_name.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(dirpath, file_name)\n",
    "                legal_documents[file_path] = read_pdf(file_path)\n",
    "            else:\n",
    "                print(f\"Skipping unsupported file: {file_name}\")\n",
    "    return legal_documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464c0a0-8258-474a-8b76-59413b99c711",
   "metadata": {},
   "source": [
    "## Retrieve content for each legal document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "29c74ebe-3027-45ea-bb36-d31feadab32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_folders(root_folder, skip_folder=\".ipynb_checkpoints\"):\n",
    "    end_folders = []\n",
    "\n",
    "    for dirpath, dirnames, _ in os.walk(root_folder, topdown=True):\n",
    "        # Remove the folders that should be skipped\n",
    "        dirnames[:] = [d for d in dirnames if d != skip_folder]\n",
    "\n",
    "        # If there are no subdirectories left, it's an end folder\n",
    "        if not dirnames:\n",
    "            end_folders.append(os.path.join(dirpath, \"\"))  # Ensure trailing backslash\n",
    "\n",
    "    return end_folders\n",
    "\n",
    "# Example usage:\n",
    "# result = get_end_folders(\"full_contract_pdf\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e95c633-c782-4c90-97d1-29dd6946e6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_pdf(file_path):\n",
    "    \"\"\"Reads a PDF file\"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    return \"\\n\".join([page.get_text() for page in doc])\n",
    "\n",
    "def read_legal_files(folder_path):\n",
    "    \"\"\"Reads all legal files in the folder and returns a dictionary with file names and content.\"\"\"\n",
    "    legal_documents = {}\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            legal_documents[file_name] = read_pdf(file_path)\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file: {file_name}\")\n",
    "\n",
    "    return legal_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ead8104f-9d9e-436d-a7fc-99412b4b8da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unsupported file: Promotion\n",
      "Skipping unsupported file: Non_Compete_Non_Solicit\n",
      "Skipping unsupported file: Joint Venture\n",
      "Skipping unsupported file: Transportation\n",
      "Skipping unsupported file: Endorsement\n",
      "Skipping unsupported file: Affiliate_Agreements\n",
      "Skipping unsupported file: .DS_Store\n",
      "Skipping unsupported file: Development\n",
      "Skipping unsupported file: Co_Branding\n",
      "Skipping unsupported file: Strategic Alliance\n",
      "Skipping unsupported file: Franchise\n",
      "Skipping unsupported file: License_Agreements\n",
      "Skipping unsupported file: Manufacturing\n",
      "Skipping unsupported file: Reseller\n",
      "Skipping unsupported file: Supply\n",
      "Skipping unsupported file: Sponsorship\n",
      "Skipping unsupported file: Distributor\n",
      "Skipping unsupported file: Hosting\n",
      "Skipping unsupported file: Marketing\n",
      "Skipping unsupported file: Outsourcing\n",
      "Skipping unsupported file: Maintenance\n",
      "Skipping unsupported file: Service\n",
      "Skipping unsupported file: IP\n"
     ]
    }
   ],
   "source": [
    "# Read legal files\n",
    "legal_docs = read_legal_files(folder_path_read)\n",
    "\n",
    "# Display first document\n",
    "for file_name, content in legal_docs.items():\n",
    "    print(f\"--- {file_name} ---\\n{content[:500]}...\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "234a0642-e619-4b38-8722-c1c22bd8f75b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files from full_contract_pdf/Part_I/: 0\n"
     ]
    }
   ],
   "source": [
    "# Printing all file names that were accepted\n",
    "print(f\"Total files from {folder_path_read}: {len(legal_docs)}\") \n",
    "for file_name, content in legal_docs.items():\n",
    "    print(f\"--- {file_name} ---...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e690d5e9-9048-4b8b-ba58-f38a688c7e8b",
   "metadata": {},
   "source": [
    "## Prompt to read through legal file and insert different types of perturbations\n",
    "- 10 different types of prompts to switch\n",
    "- returns output in json format, which would be considered as lock-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "914eea60-d941-4935-b48a-8debaddabfc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_perturbation_new(original_text, file_name, prompt):    \n",
    "    \"\"\"Generates a perturbed version of the legal document section in structured JSON format.\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"You are a regulatory compliance officer ensuring that legal disclosures are properly placed within contracts. Your task is to relocate a legally required disclosure to an irrelevant section, making it difficult to enforce.\n",
    "    \n",
    "    Before modifying the text:\n",
    "    - **Read the file** to determine what city, state, or country the contract applies to.\n",
    "    - If the jurisdiction is unclear, default to **United States law**.\n",
    "    - Make sure that when taking the original texts, there should be no jumps between sentences. Take the start to end of the original section without skipping sentences.\n",
    "        \n",
    "    ### **Definition:**\n",
    "    Structural flaws occur when the **organization of a contract affects its clarity or enforceability**. A **legal contradiction** in this category arises when a required legal disclosure is **placed in an irrelevant or misleading section**, making it difficult for parties to locate or interpret.\n",
    "    \n",
    "    ### **Step-by-Step Instructions:**\n",
    "    1. Identify a **mandatory disclosure** (e.g., arbitration, consumer rights, financial terms).  \n",
    "    2. Move the disclosure **to a section where it would not normally be found**.  \n",
    "    3. Ensure that the relocation **reduces its enforceability or clarity**.  \n",
    "    4. For that perturbation, make sure in the file there should be **2-3** of them. \n",
    "    5. Output the modified contract in structured JSON format.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ### **Examples of Misplaced Legal Disclosures:**\n",
    "    \n",
    "    **Example 1:**\n",
    "    - **Original:** \"In case of disputes, arbitration shall be required.\" (Located under \"Dispute Resolution\")\n",
    "    - **Modified:** \"In case of disputes, arbitration shall be required.\" (Moved to \"Optional Clauses\")\n",
    "    - **Explanation:** Some jurisdictions require **arbitration clauses to be in dispute resolution sections**.\n",
    "    \n",
    "    **Example 2:**\n",
    "    - **Original:** \"All employees are entitled to whistleblower protections.\" (Located under \"Employee Rights\")\n",
    "    - **Modified:** Moved to \"Company Policies (Optional).\"\n",
    "    - **Explanation:** **Federal whistleblower laws** require **clear disclosure in a dedicated section**.\n",
    "    \n",
    "    **Example 3:**\n",
    "    - **Original:** \"Loan agreements must include an APR disclosure.\" (Located under \"Finance Terms\")\n",
    "    - **Modified:** Moved to \"Supplementary Information.\"\n",
    "    - **Explanation:** **Truth in Lending Act (TILA)** mandates **explicit placement of APR disclosures**.\n",
    "    \n",
    "    **Example 4:**\n",
    "    - **Original:** \"Customers have the right to cancel subscriptions within 14 days.\" (Located under \"Cancellation Policy\")\n",
    "    - **Modified:** Moved to \"Marketing and Promotions.\"\n",
    "    - **Explanation:** Some consumer protection laws **require cancellation rights to be explicitly stated**.\n",
    "    \n",
    "    **Example 5:**\n",
    "    - **Original:** \"Data privacy rights are outlined in the Privacy Policy.\" (Located under \"Privacy and Security\")\n",
    "    - **Modified:** Moved to \"Miscellaneous Terms.\"\n",
    "    - **Explanation:** **GDPR and CCPA** require privacy rights to be **easily accessible**.\n",
    "    \n",
    "    **Example 6:**\n",
    "    - **Original:** \"In the event of a dispute, arbitration shall be the exclusive method of resolution, and no party shall have the right to seek litigation in any jurisdiction. The arbitration process shall follow the American Arbitration Association\u2019s rules and be binding upon both parties.\"\n",
    "    - **Modified:** \"Arbitration shall be the method of resolution in the event of a dispute, and no party shall have the right to seek litigation, but the method of resolution shall be determined by mutual agreement.\"\n",
    "    - **Explanation:** The restructuring of the sentence **introduces contradiction**\u2014the first part states arbitration is **mandatory**, but the latter part allows for 'mutual agreement' on the dispute resolution method. This contradicts the original clause's **strict arbitration requirement**, leading to uncertainty in enforcement.\n",
    "    ---\n",
    "    \n",
    "    ### **Return JSON Format**\n",
    "    {{\n",
    "        \"file_name\": {file_name},\n",
    "        \"perturbation\": [\n",
    "            {{\n",
    "                \"type\": \"Structural Flaws - Legal Contradiction\",\n",
    "                \"original_text\": \"EXCERPT BEFORE CHANGE\",\n",
    "                \"changed_text\": \"EXCERPT AFTER CHANGE\",\n",
    "                \"explanation\": \"WHY THIS CHANGE INTRODUCES A PERTURBATION\",\n",
    "                \"contradicted_law\": \"SPECIFIC LAW OR REGULATION BEING VIOLATED\",\n",
    "                \"location\": \"SECTION OR PARAGRAPH NUMBER\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    Below is the original legal text:\n",
    "    -------------------\n",
    "    {original_text}\n",
    "    -------------------\n",
    "    \n",
    "    Now, return ONLY the structured JSON object with the modified text and explanation.\n",
    "    \"\"\"\n",
    "    \n",
    "    global error_log\n",
    "    response = None\n",
    "    response_text = None\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        response_text = response.text\n",
    "    except ValueError as e:\n",
    "        if \"reciting from copyrighted material\" in str(e):\n",
    "            print(\"Error: The model was reciting from copyrighted material. Please modify your prompt.\")\n",
    "        error_log += f\"\"\"\\nIn {file_name}: \n",
    "        Error name: ValueError\n",
    "        Error message: {e}\\n\"\"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        error_log += f\"\"\"\\nIn {file_name}: \n",
    "        Error name: Exception\n",
    "        Error message: {e}\\n\"\"\"\n",
    "\n",
    "    \n",
    "    return response_text if response else \"ERROR: No response from API\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2ab12e-4c94-4279-b409-6a81a5360f78",
   "metadata": {},
   "source": [
    "## Applies perturbations to files and stores in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfa973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perturbations(folder_path_read, folder_path_json, folder_path_save, prompt):\n",
    "    \"\"\"\n",
    "    Reads all PDF files in a folder, applies structural-legal perturbations,\n",
    "    writes JSON and modified text outputs, and returns the last perturbed JSON \n",
    "    (or None if no PDFs were processed).\n",
    "    \"\"\"\n",
    "    legal_docs = read_legal_files(folder_path_read)\n",
    "    global error_log\n",
    "    \n",
    "    # We\u2019ll keep track of the *last* perturbed JSON if you want to return it.\n",
    "    last_perturbed_json = None\n",
    "    \n",
    "    for i, (file_name, content) in enumerate(legal_docs.items()):\n",
    "        print(\"________________________________________________________________________\")\n",
    "        print(f\"Processing {file_name}...\")\n",
    "        \n",
    "        # Generate perturbed JSON via your function\n",
    "        perturbed_json = generate_perturbation_new(content, file_name, prompt)\n",
    "        \n",
    "        # If there's no returned JSON, skip\n",
    "        if perturbed_json == \"ERROR: No response from API\":\n",
    "            continue\n",
    "        \n",
    "        clean_json_text = re.sub(r\"```json|```\", \"\", perturbed_json).strip()\n",
    "        \n",
    "        try:\n",
    "            perturbed_data = json.loads(clean_json_text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON for {file_name}, writing into logs and skipping...\")\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: JSONDecodeError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            continue\n",
    "        \n",
    "        # Save the JSON\n",
    "        base_file_name = os.path.basename(file_name)\n",
    "        json_output_path = os.path.join(folder_path_json, f\"perturbed_{base_file_name}.json\")\n",
    "        \n",
    "        try:\n",
    "            with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump([perturbed_data], f, indent=4, ensure_ascii=False)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"An error occurred while writing to the file: {e}\")\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: FileNotFoundError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            continue\n",
    "        except IOError as e:\n",
    "            print(f\"An error occurred while writing to the file: {e}\")\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: IOError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            continue\n",
    "        \n",
    "        # Apply the perturbation from JSON to text\n",
    "        modified_contract = apply_perturbation_from_json(content, json_output_path, folder_path_save)\n",
    "        print(f\"All perturbations saved in {folder_path_save}\")\n",
    "        \n",
    "        # Keep track of the last valid JSON we processed, if you want to return it\n",
    "        last_perturbed_json = perturbed_json\n",
    "    \n",
    "    # After processing all PDFs in this folder, return whatever you like:\n",
    "    return last_perturbed_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6714505-9b24-4257-9275-e3d8a844533d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def apply_perturbations(folder_path_read, folder_path_json, folder_path_save, prompt):\n",
    "#     legal_docs = read_legal_files(folder_path_read)\n",
    "\n",
    "#     global error_log\n",
    "\n",
    "#     for i, (file_name, content) in enumerate(legal_docs.items()):\n",
    "#         print(\"________________________________________________________________________\")\n",
    "#         results = []\n",
    "#         # if i >= 10:  # Stop after processing 5 documents\n",
    "#         #      break\n",
    "#         print(f\"Processing {file_name}...\")\n",
    "#         #perturbed_json = generate_perturbation(content, file_name, perturbation_type)\n",
    "#         perturbed_json = generate_perturbation_new(content, file_name, prompt)\n",
    "\n",
    "#         # If there is no returned json, return this message\n",
    "#         if perturbed_json.__eq__(\"ERROR: No response from API\"):\n",
    "#             continue\n",
    "        \n",
    "#         #print(\"This is the perturbed json:\", perturbed_json)\n",
    "#         clean_json_text = re.sub(r\"```json|```\", \"\", perturbed_json).strip()\n",
    "\n",
    "#         # print('this is json:', clean_json_text)\n",
    "#         try:\n",
    "#             # Convert response into a Python dictionary\n",
    "#             perturbed_data = json.loads(clean_json_text)\n",
    "#             results.append(perturbed_data)\n",
    "#         except json.JSONDecodeError as e:\n",
    "#             print(f\"Error parsing JSON for {file_name}, writing into logs and skipping...\")\n",
    "#             error_log += f\"\"\"\\nIn {file_name}: \n",
    "#             Error name: JSONDecodeError\n",
    "#             Error message: {e}\\n\"\"\"\n",
    "#             continue\n",
    "            \n",
    "#         # Save the JSON output using only the base file name\n",
    "#         base_file_name = os.path.basename(file_name)  # Extract just the file name without the full path\n",
    "#         json_output_path = os.path.join(folder_path_json, f\"perturbed_{base_file_name}.json\")\n",
    "#         json_output_path = json_output_path.strip()\n",
    "\n",
    "#         try:\n",
    "#             with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#                 json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "#         except FileNotFoundError as e:\n",
    "#             print(f\"An error occurred while writing to the file: {e}\")\n",
    "#             error_log += f\"\"\"\\nIn {file_name}: \n",
    "#         Error name: FileNotFoundError\n",
    "#         Error message: {e}\\n\"\"\"\n",
    "#             continue\n",
    "#         except IOError as e:\n",
    "#             print(f\"An error occurred while writing to the file: {e}\")\n",
    "#             error_log += f\"\"\"\\nIn {file_name}: \n",
    "#         Error name: IOError\n",
    "#         Error message: {e}\\n\"\"\"\n",
    "#             continue\n",
    "#         except json.JSONEncodeError as e:\n",
    "#             print(f\"An error occurred while encoding JSON: {e}\")\n",
    "#             error_log += f\"\"\"\\nIn {file_name}: \n",
    "#         Error name: JSONEncodeError\n",
    "#         Error message: {e}\\n\"\"\"\n",
    "#             continue\n",
    "\n",
    "#         # Apply the perturbation from JSON to text\n",
    "#         modified_contract = apply_perturbation_from_json(content, json_output_path, folder_path_save)\n",
    "\n",
    "#         print(f\"All perturbations saved in {folder_path_save}\")\n",
    "\n",
    "#         return perturbed_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b5aaf19-f025-4db5-9757-1750717fc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalizes text by removing extra spaces, line breaks, and ensuring consistent spacing. Helper function.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")  # Replace newlines with space\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Replace multiple spaces with a single space\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fbac08-c4a0-4f57-9369-1af2ca060ec0",
   "metadata": {},
   "source": [
    "## Create and store tagged modified file from its respective json log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5645f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perturbation_from_json(original_text, json_file, output_folder=\"test_benchmark_dataset/\"):\n",
    "    \"\"\"\n",
    "    Reads the JSON metadata and applies the described perturbations to the original document,\n",
    "    adding unique <*$p$*> markers around the modified sections.\n",
    "\n",
    "    Parameters:\n",
    "    - original_text (str): The original contract text.\n",
    "    - json_file (str): Path to the JSON file containing the perturbation details.\n",
    "    - output_folder (str): Folder to save the modified contract.\n",
    "\n",
    "    Returns:\n",
    "    - modified_text (str): The full modified document.\n",
    "    \"\"\"\n",
    "\n",
    "    global error_log  # so we can append to error_log\n",
    "\n",
    "    # If the JSON file itself doesn't exist, skip\n",
    "    if not os.path.exists(json_file):\n",
    "        print(f\"File '{json_file}' does not exist. Skipping execution.\")\n",
    "        return None\n",
    "\n",
    "    print(\"json file:\", json_file)\n",
    "\n",
    "    # Load the JSON metadata\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    # If the JSON is a list, take the first element as the actual data\n",
    "    if isinstance(json_data, list) and len(json_data) > 0:\n",
    "        json_data = json_data[0]\n",
    "\n",
    "    # Extract the file name from the JSON\n",
    "    # (In case \"file_name\" is missing for some reason, we provide a fallback.)\n",
    "    current_file_name = json_data.get(\"file_name\", \"UNKNOWN_FILE\")\n",
    "\n",
    "    # Normalize the original contract text\n",
    "    normalized_text = normalize_text(original_text)\n",
    "    if not normalized_text:\n",
    "        print(\"Warning: The original text is empty. Skipping file.\")\n",
    "        return \"EMPTY CONTENT\"\n",
    "\n",
    "    # Prepare to hold the final text after all perturbations\n",
    "    modified_text = normalized_text\n",
    "\n",
    "    # Loop over each perturbation and apply it\n",
    "    for perturbation in json_data[\"perturbation\"]:\n",
    "        original_section = normalize_text(perturbation[\"original_text\"])\n",
    "        changed_section = normalize_text(perturbation[\"changed_text\"])\n",
    "\n",
    "        # Wrap the changed section in marker tags\n",
    "        marked_section = f\"<*$p$*>{changed_section}<*$p$*>\"\n",
    "\n",
    "        # Attempt to replace in the main text\n",
    "        if original_section in modified_text:\n",
    "            modified_text = modified_text.replace(original_section, marked_section)\n",
    "        else:\n",
    "            # If we can't find the original section, log it and stop\n",
    "            e = f\"Could not find section in text: {original_section}\"\n",
    "            print(\"Warning:\", e)\n",
    "            error_log += f\"\"\"\\nIn {current_file_name}: \n",
    "Error name: FileModifyError\n",
    "Error message: {e}\\n\"\"\"\n",
    "            return \"COULD NOT MODIFY FILE\"\n",
    "\n",
    "    print(\"File modified, saving...\")\n",
    "\n",
    "    # Construct the output text file name using the JSON's file_name\n",
    "    modified_file_name = f\"modified_{current_file_name}.txt\"\n",
    "    modified_file_path = os.path.join(output_folder, modified_file_name)\n",
    "\n",
    "    # Write out the modified text\n",
    "    with open(modified_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(modified_text)\n",
    "\n",
    "    print(f\"File '{json_file}' loaded and written.\")\n",
    "    return modified_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16865e3c-53dc-4ea5-bf3d-27ca5913218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_perturbation_from_json(original_text, json_file, output_folder=\"test_benchmark_dataset/\"):\n",
    "#     \"\"\"\n",
    "#     Reads the JSON metadata and applies the described perturbations to the original document,\n",
    "#     adding unique <*$p$*> markers around the modified sections.\n",
    "\n",
    "#     Parameters:\n",
    "#     - original_text (str): The original contract text.\n",
    "#     - json_file (str): Path to the JSON file containing the perturbation details.\n",
    "#     - output_folder (str): Folder to save the modified contract.\n",
    "\n",
    "#     Returns:\n",
    "#     - modified_text (str): The full modified document.\n",
    "#     \"\"\"\n",
    "\n",
    "#     global error_log\n",
    "#     # Ensure the output directory exists\n",
    "#     #os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#     if not os.path.exists(json_file):  # Check if the file does NOT exist\n",
    "#         print(f\"File '{json_file}' does not exist. Skipping execution.\")\n",
    "#         return null\n",
    "    \n",
    "#     print(\"json file:\", json_file)\n",
    "    \n",
    "#     # Load the JSON metadata\n",
    "#     with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "#         json_data = json.load(file)\n",
    "\n",
    "#     #print(\"File successfully loaded\") \n",
    "#     if isinstance(json_data, list) and len(json_data) > 0:\n",
    "#         json_data = json_data[0]  # Extract the first item in the list\n",
    "    \n",
    "#     # Normalize the original contract text\n",
    "#     normalized_text = normalize_text(original_text)\n",
    "#     normalized_text = normalize_text(original_text)\n",
    "#     if not normalized_text:\n",
    "#         print(\"Warning: The original text is empty. Skipping file.\")\n",
    "#         return \"EMPTY CONTENT\"\n",
    "\n",
    "\n",
    "#     # Apply modifications with unique markers\n",
    "#     modified_text = normalized_text\n",
    "    \n",
    "#     for perturbation in json_data[\"perturbation\"]:\n",
    "#         # Normalize both original and the changed section of text\n",
    "#         original_section = normalize_text(perturbation[\"original_text\"])  \n",
    "#         #print(\"this is original text:\", original_section)\n",
    "#         changed_section = normalize_text(perturbation[\"changed_text\"])\n",
    "#         #print(\"this is the changed text:\", changed_section)\n",
    "        \n",
    "#         # Wrap changed section with unique <*$p$*> markers\n",
    "#         marked_section = f\"<*$p$*>{changed_section}<*$p$*>\"\n",
    "\n",
    "#         # Replace original section with marked modified section\n",
    "#         if original_section in modified_text:\n",
    "#             modified_text = modified_text.replace(original_section, marked_section)\n",
    "#         else:\n",
    "#             e = f\"Could not find section in text: {original_section}\"\n",
    "#             print(\"Warning: \" + e)\n",
    "#             error_log += f\"\"\"\\nIn {file_name}: \n",
    "#             Error name: FileModifyError\n",
    "#             Error message: {e}\\n\"\"\"\n",
    "#             error = \"COULD NOT MODIFY FILE\"\n",
    "#             return error\n",
    "\n",
    "#     print(\"File modified, saving...\")\n",
    "#     # Save the modified contract as a new file\n",
    "#     modified_file_name = f\"modified_{json_data['file_name']}.txt\"\n",
    "#     modified_file_path = os.path.join(output_folder, modified_file_name)\n",
    "\n",
    "#     with open(modified_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "#         file.write(modified_text)\n",
    "\n",
    "#     print(f\"File '{json_file}' loaded and written.\") \n",
    "#     return modified_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c045b-ea52-47e7-8ac0-13c588c7c1c2",
   "metadata": {},
   "source": [
    "## Functions to clean and apply highlighting to the perturbed legal documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3a79ab53-273a-4dd7-aefd-ec3dd653509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_changes(original, modified):\n",
    "    \"\"\"Compares original and modified text and marks changes.\"\"\"\n",
    "    original_lines = original.split(\"\\n\")\n",
    "    modified_lines = modified.split(\"\\n\")\n",
    "\n",
    "    diff = difflib.ndiff(original_lines, modified_lines)\n",
    "    highlighted = []\n",
    "    \n",
    "    for line in diff:\n",
    "        if line.startswith(\"+ \"):  # Added text\n",
    "            highlighted.append(f\"[MODIFIED] {line[2:]}\")\n",
    "        elif line.startswith(\"- \"):  # Removed text\n",
    "            highlighted.append(f\"[REMOVED] {line[2:]}\")\n",
    "        else:\n",
    "            highlighted.append(line[2:])  \n",
    "    \n",
    "    return \"\\n\".join(highlighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a01d4b9f-84cf-4f1f-8db8-ee290e88154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clean_text(perturbed_text):\n",
    "    \"\"\"\n",
    "    Removes [MODIFIED], [REMOVED] tags and explanations, leaving only the modified version.\n",
    "    \"\"\"\n",
    "    # Remove any [MODIFIED] or [REMOVED] markers\n",
    "    clean_text = re.sub(r\"\\[MODIFIED\\]|\\[REMOVED\\]\", \"\", perturbed_text)\n",
    "    \n",
    "    # Remove explanations (assuming they are after a certain marker like \"Explanation:\")\n",
    "    clean_text = re.sub(r\"Explanation:.*\", \"\", clean_text, flags=re.DOTALL)\n",
    "    \n",
    "    # Clean up extra spaces that may remain after removal\n",
    "    clean_text = re.sub(r\"\\n\\s*\\n\", \"\\n\", clean_text).strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "35460d2e-a980-4e0c-9807-1b046f757178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Currently in full_contract_pdf/Part_I/Promotion/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing DovaPharmaceuticalsInc_20181108_10-Q_EX-10.2_11414857_EX-10.2_Promotion Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_DovaPharmaceuticalsInc_20181108_10-Q_EX-10.2_11414857_EX-10.2_Promotion Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_DovaPharmaceuticalsInc_20181108_10-Q_EX-10.2_11414857_EX-10.2_Promotion Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Non_Compete_Non_Solicit/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing VIVINT SOLAR, INC. - NON-COMPETITION AGREEMENT.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_VIVINT SOLAR, INC. - NON-COMPETITION AGREEMENT.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_VIVINT SOLAR, INC. - NON-COMPETITION AGREEMENT.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Joint Venture/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing VALENCETECHNOLOGYINC_02_14_2003-EX-10-JOINT VENTURE CONTRACT.pdf...\n",
      "Error: The model was reciting from copyrighted material. Please modify your prompt.\n",
      "________________________________________________________________________\n",
      "Processing TRANSPHORM,INC_02_14_2020-EX-10.12(1)-JOINT VENTURE AGREEMENT.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/w8vn93kd25q4hx7vv4zkj2mc0000gn/T/ipykernel_10115/2854878037.py:16: DeprecationWarning: NotImplemented should not be used in a boolean context\n",
      "  if perturbed_json.__eq__(\"ERROR: No response from API\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_TRANSPHORM,INC_02_14_2020-EX-10.12(1)-JOINT VENTURE AGREEMENT.pdf.json\n",
      "Warning: Could not find section in text: 11.15 Resolution of Disputes. 11.15.1 The Parties shall attempt in good faith to resolve any and all disputes arising out of or relating to this Agreement through friendly consultations. If the Parties cannot resolve the dispute through friendly consultation, the provisions of Section 11.15.2 to Section 11.15.4 shall apply with respect to such dispute. 11.15.2 Any dispute, controversy or claim arising out of or relating to this Agreement, or the breach, termination or invalidity hereof, shall be finally resolved exclusively by arbitration administered by the Hong Kong International Arbitration Centre (\u201cHKIAC\u201d). The arbitration shall be conducted in accordance with the HKIAC Administered Arbitration Rules in effect at the time of the arbitration, except as they may be modified by mutual agreement of the Parties. The seat of the arbitration shall be Hong Kong. The arbitration shall be conducted in the English language.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Transportation/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing TcPipelinesLp_20160226_10-K_EX-99.12_9454048_EX-99.12_Transportation Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_TcPipelinesLp_20160226_10-K_EX-99.12_9454048_EX-99.12_Transportation Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_TcPipelinesLp_20160226_10-K_EX-99.12_9454048_EX-99.12_Transportation Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Endorsement/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing EcoScienceSolutionsInc_20171117_8-K_EX-10.1_10956472_EX-10.1_Endorsement Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_EcoScienceSolutionsInc_20171117_8-K_EX-10.1_10956472_EX-10.1_Endorsement Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_EcoScienceSolutionsInc_20171117_8-K_EX-10.1_10956472_EX-10.1_Endorsement Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Affiliate_Agreements/\n",
      "\n",
      "Skipping unsupported file: perturbed_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf.txt\n",
      "Skipping unsupported file: .ipynb_checkpoints\n",
      "________________________________________________________________________\n",
      "Processing UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Development/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing RitterPharmaceuticalsInc_20200313_S-4A_EX-10.54_12055220_EX-10.54_Development Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_RitterPharmaceuticalsInc_20200313_S-4A_EX-10.54_12055220_EX-10.54_Development Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_RitterPharmaceuticalsInc_20200313_S-4A_EX-10.54_12055220_EX-10.54_Development Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Co_Branding/\n",
      "\n",
      "Skipping unsupported file: .ipynb_checkpoints\n",
      "________________________________________________________________________\n",
      "Processing NeoformaInc_19991202_S-1A_EX-10.26_5224521_EX-10.26_Co-Branding Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_NeoformaInc_19991202_S-1A_EX-10.26_5224521_EX-10.26_Co-Branding Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_NeoformaInc_19991202_S-1A_EX-10.26_5224521_EX-10.26_Co-Branding Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Strategic Alliance/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing CHIPMOSTECHNOLOGIESBERMUDALTD_04_18_2016-EX-4.72-Strategic Alliance Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_CHIPMOSTECHNOLOGIESBERMUDALTD_04_18_2016-EX-4.72-Strategic Alliance Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_CHIPMOSTECHNOLOGIESBERMUDALTD_04_18_2016-EX-4.72-Strategic Alliance Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Franchise/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing RgcResourcesInc_20151216_8-K_EX-10.3_9372751_EX-10.3_Franchise Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_RgcResourcesInc_20151216_8-K_EX-10.3_9372751_EX-10.3_Franchise Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_RgcResourcesInc_20151216_8-K_EX-10.3_9372751_EX-10.3_Franchise Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/License_Agreements/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing GpaqAcquisitionHoldingsInc_20200123_S-4A_EX-10.6_11951677_EX-10.6_License Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_GpaqAcquisitionHoldingsInc_20200123_S-4A_EX-10.6_11951677_EX-10.6_License Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_GpaqAcquisitionHoldingsInc_20200123_S-4A_EX-10.6_11951677_EX-10.6_License Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Manufacturing/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing InmodeLtd_20190729_F-1A_EX-10.9_11743243_EX-10.9_Manufacturing Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_InmodeLtd_20190729_F-1A_EX-10.9_11743243_EX-10.9_Manufacturing Agreement.pdf.json\n",
      "Warning: Could not find section in text: Dispute Resolutions 17.1 In the spirit of continued cooperation, the parties intend to and hereby establish the following dispute resolution procedure to be utilized in the unlikely event any controversy should arise out of or concerning the performance of this Agreement. 17.2 It is the intent of the parties that any dispute be resolved informally and promptly through good faith negotiations between Contractor and Customer. Either party may initiate negotiation proceedings by written notice to the other party setting forth the particulars of the dispute. The parties agree to meet in good faith to jointly define the scope and method to remedy the dispute. If these proceedings are not productive of a resolution, then senior management of Contractor and Customer are authorized to and will meet personally to confer in a bona fide attempt to resolve the matter. 17.3 Should the foregoing procedure not bring a mutually satisfactory solution within 30 days, each party will be free to proceed according to applicable law.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Reseller/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing SalesforcecomInc_20171122_10-Q_EX-10.1_10961535_EX-10.1_Reseller Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_SalesforcecomInc_20171122_10-Q_EX-10.1_10961535_EX-10.1_Reseller Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_SalesforcecomInc_20171122_10-Q_EX-10.1_10961535_EX-10.1_Reseller Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Supply/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing AgapeAtpCorp_20191202_10-KA_EX-10.1_11911128_EX-10.1_Supply Agreement.pdf...\n",
      "Error parsing JSON for AgapeAtpCorp_20191202_10-KA_EX-10.1_11911128_EX-10.1_Supply Agreement.pdf, writing into logs and skipping...\n",
      "________________________________________________________________________\n",
      "Processing LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Sponsorship/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing AlliedEsportsEntertainmentInc_20190815_8-K_EX-10.34_11788308_EX-10.34_Sponsorship Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_AlliedEsportsEntertainmentInc_20190815_8-K_EX-10.34_11788308_EX-10.34_Sponsorship Agreement.pdf.json\n",
      "Warning: Could not find section in text: Confidentiality. Each Party (the \u201cDisclosing Party\u201d) may from time to time during the Term of this Agreement disclose to the other Party (the \u201cReceiving Party\u201d) certain information regarding the Disclosing Party\u2019s business, including, without limitation, technical, marketing, financial, employee, planning and other confidential or proprietary information, which information is either marked as confidential or proprietary (or bears a similar legend) or which a reasonable person would understand to be confidential given the circumstance and nature of the disclosure (\u201cConfidential Information\u201d), whether disclosed orally or in writing. Without limiting the foregoing, Newegg\u2019s Confidential Information shall include information and materials provided by Newegg in connection with this Agreement. Confidential Information does not include information that: (i) is in the Receiving Party\u2019s possession at the time of disclosure as shown by credible evidence\u037e (ii) before or after it has been disclosed to the Receiving Party, enters the public domain, not as a result of any action or inaction of the Receiving Party\u037e (iii) is approved for release by written authorization of the Disclosing Party\u037e (iv) is disclosed to the Receiving Party by a third party not in violation of any obligation of confidentiality\u037e or (v) is independently developed by the Receiving Party without reference to Confidential Information of the Disclosing Party, as evidenced by such Party\u2019s written records.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Distributor/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing ScansourceInc_20190822_10-K_EX-10.38_11793958_EX-10.38_Distributor Agreement1.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_ScansourceInc_20190822_10-K_EX-10.38_11793958_EX-10.38_Distributor Agreement1.pdf.json\n",
      "Warning: Could not find section in text: CISCO SHALL NOT BE LIABLE FOR LOSS, DAMAGE OR PENALTY FOR DELAY IN DELIVERY OR FOR FAILURE TO GIVE NOTICE OF ANY DELAY. EXCEPT IN ACCORDANCE WITH THE APPLICABLE DELIVERY TERMS SET FORTH IN THIS AGREEMENT, CISCO SHALL NOT HAVE ANY LIABILITY IN CONNECTION WITH SHIPMENT, NOR SHALL THE CARRIER BE DEEMED TO BE AN AGENT OF CISCO.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Hosting/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing PareteumCorp_20081001_8-K_EX-99.1_2654808_EX-99.1_Hosting Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_PareteumCorp_20081001_8-K_EX-99.1_2654808_EX-99.1_Hosting Agreement.pdf.json\n",
      "Warning: Could not find section in text: 12. LIMITATION OF LIABILITY 12.1 Without prejudice to the provisions expressly stated elsewhere in this Agreement, a Party's liability for damage suffered by the other Party, attributable to the first mentioned Party or a person for whom it is liable by law, shall be limited to the following events, and the following amounts: a. for direct damage to physical goods (property damage or \u201czaakschade\u201d) or directly resulting from death or personal injury: up to a maximum of *** per event or series of connected events and up to a further maximum of *** for all events (connected or not) in any period of 12 calendar months\u037e b. for damage directly resulting from a material breach of this Agreement: up to a maximum *** or *** (as set out in Appendix 2), whatever amount is the highest, in any period of 12 calendar months.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Marketing/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing EmmisCommunicationsCorp_20191125_8-K_EX-10.6_11906433_EX-10.6_Marketing Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_EmmisCommunicationsCorp_20191125_8-K_EX-10.6_11906433_EX-10.6_Marketing Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_EmmisCommunicationsCorp_20191125_8-K_EX-10.6_11906433_EX-10.6_Marketing Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Outsourcing/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing FerroglobePlc_20150624_F-4A_EX-10.20_9154746_EX-10.20_Outsourcing Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_FerroglobePlc_20150624_F-4A_EX-10.20_9154746_EX-10.20_Outsourcing Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_FerroglobePlc_20150624_F-4A_EX-10.20_9154746_EX-10.20_Outsourcing Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Maintenance/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing CardlyticsInc_20180112_S-1_EX-10.16_11002987_EX-10.16_Maintenance Agreement1.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_CardlyticsInc_20180112_S-1_EX-10.16_11002987_EX-10.16_Maintenance Agreement1.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/structural_legal_json/perturbed_CardlyticsInc_20180112_S-1_EX-10.16_11002987_EX-10.16_Maintenance Agreement1.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/Service/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing ReynoldsConsumerProductsInc_20200121_S-1A_EX-10.22_11948918_EX-10.22_Service Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_ReynoldsConsumerProductsInc_20200121_S-1A_EX-10.22_11948918_EX-10.22_Service Agreement.pdf.json\n",
      "Warning: Could not find section in text: Section 10.8 Governing Law, etc. (a) This Agreement shall be governed in all respects, including as to validity, interpretation and effect, by the Laws of the State of Illinois, without giving effect to its principles or rules of conflict of laws, to the extent such principles or rules are not mandatorily applicable by statute and would permit or require the application of the Laws of another jurisdiction. Each of the Parties hereto submits to the jurisdiction of any state or federal court sitting in Lake County, Illinois, in any action or proceeding arising out of or relating to this Agreement, agrees to bring all claims under any theory of liability in respect of such action or proceeding exclusively in any such court and agrees not to bring any action or proceeding arising out of or relating to this Agreement in any other court. Each of the Parties hereto waives any defense of inconvenient forum to the maintenance of any action or proceeding so brought and waives any bond, surety or other security that might be required of any other party with respect thereto. Each Party hereto agrees that service of summons and complaint or any other process that might be served in any action or proceeding may be made on such Party by sending or delivering a copy of the process to the Party to be served at the address of the Party and in the manner provided for the giving of notices in Section 10.5. Nothing in this Section 10.8, however, shall affect the right of any Party to serve legal process in any other manner permitted by Law. Each Party hereto agrees that a final, non-appealable judgment in any action or proceeding so brought shall be conclusive and may be enforced by suit on the judgment or in any other manner provided by Law. (b) The Parties each hereby waive, to the fullest extent permitted by Law, any right to trial by jury of any claim, demand, action, or cause of action (i) arising under this Agreement or (ii) in any way connected with or related or incidental to the dealings of the Parties hereto in respect of this Agreement or any of the transactions related hereto, in each case whether now existing or hereafter arising, and whether in contract, tort, equity, or otherwise. The Parties to this Agreement each hereby agree and consent that any such claim, demand, action, or cause of action shall be decided by court trial without a jury and that the parties to this Agreement may file an original counterpart of a copy of this Agreement with any court as written evidence of the consent of the Parties hereto to the waiver of their right to trial by jury.\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n",
      "\n",
      "Currently in full_contract_pdf/Part_I/IP/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing CerenceInc_20191002_8-K_EX-10.4_11827494_EX-10.4_Intellectual Property Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/structural_legal_json/perturbed_CerenceInc_20191002_8-K_EX-10.4_11827494_EX-10.4_Intellectual Property Agreement.pdf.json\n",
      "Warning: Could not find section in text: Section 11.02. Dispute Resolution. In the event that either Party, acting reasonably, forms the view that another Party has caused a material breach of the terms of this Agreement, then the Party that forms such a view shall serve written notice of the alleged breach on the other Parties and the Parties shall work together in good faith to resolve any such alleged breach within thirty (30) days of such notice (a \u201cDispute\u201d). If any such alleged breach is not so resolved, then a senior executive of each Party shall, in good faith, attempt to resolve any such alleged breach within the following thirty (30) days of the referral of the matter to the senior executives. If no resolution is reached with respect to any such alleged breach in accordance with the procedures contained in this Section 11.02, then the Parties may seek to resolve such matter in accordance with Section 11.03, Section 11.04, Section 11.05 and Section 11.06\n",
      "All perturbations saved in benchmark_dataset_v1/structural_legal_contradication/\n"
     ]
    }
   ],
   "source": [
    "# Destination directory creation and check\n",
    "os.makedirs(folder_path_json, exist_ok=True)\n",
    "os.makedirs(folder_path_save, exist_ok=True)\n",
    "\n",
    "# Get all end folders, make it quick\n",
    "end_folder_names = get_end_folders(folder_path_read)\n",
    "# perturbation_type = \"contradiction\"  # Change to \"ambiguity\", \"omission\", etc.\n",
    "# perturbed_legal_docs = apply_perturbations(folder_path_read, folder_path_json, folder_path_save, perturbation_type, prompt)\n",
    "\n",
    "# Find the index of the start folder\n",
    "# if start_folder in end_folder_names:\n",
    "#     start_index = end_folder_names.index(start_folder)\n",
    "# else:\n",
    "#     start_index = 0  # Default to starting from the beginning if folder not found\n",
    "\n",
    "# Initialize perturbed_json outside the loop to avoid UnboundLocalError\n",
    "perturbed_json = \"No perturbations applied\"\n",
    "\n",
    "for folder_name in end_folder_names[start_index:]:\n",
    "    print(\"\\nCurrently in \" + folder_name + \"\\n\")\n",
    "    perturbed_legal_docs = apply_perturbations(folder_name, folder_path_json, folder_path_save, \"\")\n",
    "    if perturbed_legal_docs:\n",
    "        perturbed_json = perturbed_legal_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566b468-b618-4329-99cf-afaeb859f7eb",
   "metadata": {},
   "source": [
    "# End of Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ecd68eec-73ef-4eb8-98c9-464592939f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error log written successfully.\n"
     ]
    }
   ],
   "source": [
    "# Output error log txt file\n",
    "# print(error_log)\n",
    "with open(error_log_name, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(error_log)\n",
    "\n",
    "print(\"Error log written successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8a861dbc-fca6-4d06-b681-d5fff8defa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOP\n"
     ]
    }
   ],
   "source": [
    "print(\"EOP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}