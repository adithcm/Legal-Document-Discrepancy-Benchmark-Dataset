{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45c6acc-8851-4b17-ba0c-2ae651c039f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (0.8.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-generativeai) (2.164.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-generativeai) (1.10.8)\n",
      "Requirement already satisfied: tqdm in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-generativeai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.69.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6addb1-0542-4e04-8d91-bb23c2b27f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /Users/adithmouli/anaconda3/lib/python3.11/site-packages (1.25.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf2eed28-2c34-4c62-80e2-68db59684a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566465eb-3e09-45f0-bda0-b4892fa05e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7eaec7b-a947-4309-b7be-ffc043275059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58c3950b-60ba-4de2-b5f7-9f3ef344a7ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine a light switch. A regular computer bit is like that light switch \u2013 it can be either on (1) or off (0). Quantum computers use something called a \"qubit,\" which is like a dimmer switch.\n",
      "\n",
      "**Instead of just being on or off, a qubit can be on, off, *or somewhere in between, all at the same time!* This \"somewhere in between\" state is called superposition.**\n",
      "\n",
      "Think of it like a coin spinning in the air. While it's spinning, it's neither heads nor tails, it's both at the same time, until it lands. A qubit is similar, it exists in multiple states simultaneously.\n",
      "\n",
      "**Why is this powerful?**\n",
      "\n",
      "*   **Parallel Processing:** Because a qubit can be in multiple states at once, a quantum computer can explore many possibilities simultaneously. This is like trying many different keys on a lock at the same time, instead of one at a time.\n",
      "*   **Complex Problems:** This parallel processing allows quantum computers to tackle complex problems that are too difficult for regular computers, like:\n",
      "    *   **Discovering new medicines and materials:** Simulating molecules and their interactions.\n",
      "    *   **Breaking modern encryption:** Cracking codes used to secure online data.\n",
      "    *   **Optimizing logistics and finance:** Finding the most efficient routes or investment strategies.\n",
      "\n",
      "**Another key concept is \"entanglement.\"**\n",
      "\n",
      "Imagine two of our spinning coins. If they're entangled, when one lands on heads, the other instantly lands on tails, even if they're far apart. Entangled qubits are linked in a special way, allowing them to work together, increasing the power of quantum computation.\n",
      "\n",
      "**So, in a nutshell:**\n",
      "\n",
      "*   **Quantum computers use qubits, which can be in multiple states at once (superposition).**\n",
      "*   **This allows them to perform calculations in parallel, solving complex problems faster.**\n",
      "*   **Entanglement links qubits together, further enhancing their power.**\n",
      "\n",
      "**Important Note:** Quantum computers are still in their early stages of development. They're not going to replace your laptop anytime soon. They're specialized tools for specific problems that regular computers can't handle.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Initialize the Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# Ask a question\n",
    "response = model.generate_content(\"Explain quantum computing in simple terms.\")\n",
    "\n",
    "# Print the response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b350490-c432-4f4e-a9df-930d2ac7d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import difflib\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08932ad4-a008-4fd6-b812-eb39ab3dbc86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_pdf(file_path):\n",
    "    \"\"\"Reads a PDF file\"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    return \"\\n\".join([page.get_text() for page in doc])\n",
    "\n",
    "def read_legal_files(folder_path):\n",
    "    \"\"\"Reads all legal files in the folder and returns a dictionary with file names and content.\"\"\"\n",
    "    legal_documents = {}\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            legal_documents[file_name] = read_pdf(file_path)\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file: {file_name}\")\n",
    "\n",
    "    return legal_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead8104f-9d9e-436d-a7fc-99412b4b8da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unsupported file: perturbed_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf.txt\n",
      "Skipping unsupported file: .ipynb_checkpoints\n",
      "--- UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf ---\n",
      "                                                                   EXHIBIT 10.11\n",
      "                         NETWORK 1 FINANCIAL CORPORATION\n",
      "                           AFFILIATE OFFICE AGREEMENT\n",
      "THIS  AGREEMENT  is  entered  into  by  and  between  NETWORK  1 FINANCIAL, INC.\n",
      "(\"NETWORK  1\"),  a  Virginia Corporation with its principal place of business at\n",
      "1501  Farm  Credit  Drive,  Suite 1500, McLean, Virginia 22102-5004, and Payment\n",
      "Data  Systems,  Inc.,  the  Affiliate Office (\"AFFILIATE\"), a Nev...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"full_contract_pdf/Part_I/Affiliate_Agreements/\"\n",
    "legal_docs = read_legal_files(folder_path)\n",
    "\n",
    "# Display first document\n",
    "for file_name, content in legal_docs.items():\n",
    "    print(f\"--- {file_name} ---\\n{content[:500]}...\\n\")\n",
    "    break  # Only show the first one for preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "234a0642-e619-4b38-8722-c1c22bd8f75b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf ---...\n",
      "\n",
      "--- DigitalCinemaDestinationsCorp_20111220_S-1_EX-10.10_7346719_EX-10.10_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- LinkPlusCorp_20050802_8-K_EX-10_3240252_EX-10_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- CreditcardscomInc_20070810_S-1_EX-10.33_362297_EX-10.33_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- SouthernStarEnergyInc_20051202_SB-2A_EX-9_801890_EX-9_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- UnionDentalHoldingsInc_20050204_8-KA_EX-10_3345577_EX-10_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- SteelVaultCorp_20081224_10-K_EX-10.16_3074935_EX-10.16_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- TubeMediaCorp_20060310_8-K_EX-10.1_513921_EX-10.1_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605784_EX-10.27_Affiliate Agreement.pdf ---...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_name, content in legal_docs.items():\n",
    "    print(f\"--- {file_name} ---...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47744679-e684-46e8-bd70-b92b918a088d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_perturbation(original_text, file_name, perturbation_type=\"contradiction\"):\n",
    "    \"\"\"Generates a perturbed version of the legal document section in structured JSON format.\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a legal expert trained in contract analysis. Below is a section from a legal document. \n",
    "    Your task is to modify it by introducing a {perturbation_type} and return the result in a structured JSON format.\n",
    "\n",
    "    Examples:\n",
    "    - Contradiction: Add a clause that conflicts with an earlier statement or national law.\n",
    "    - Ambiguity: Make a sentence vague so it can have multiple interpretations.\n",
    "    - Omission: Remove a key clause that changes the meaning significantly.\n",
    "    \n",
    "    Instructions:\n",
    "    - Apply the perturbation directly into the text.\n",
    "    - Identify and extract the exact original excerpt that was changed.\n",
    "    - Provide the changed version of the excerpt.\n",
    "    - Explain why the change introduces a {perturbation_type}.\n",
    "    - Format the output in the following JSON structure:\n",
    "    \n",
    "    {{\n",
    "        \"file_name\": {file_name},\n",
    "        \"text\": \"FULL MODIFIED DOCUMENT HERE\",\n",
    "        \"explanation\": [\n",
    "            {{\n",
    "                \"location\": \"LOCATION OF CHANGE\",\n",
    "                \"original_text\": \"EXCERPT BEFORE CHANGE\",\n",
    "                \"changed_text\": \"EXCERPT AFTER CHANGE\",\n",
    "                \"explanation\": \"WHY THIS CHANGE INTRODUCES A PERTURBATION\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    Below is the original legal text:\n",
    "    -------------------\n",
    "    {original_text}\n",
    "    -------------------\n",
    "\n",
    "    Now, return ONLY the structured JSON object with the modified text and explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text if response else \"ERROR: No response from API\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "419800a2-f881-45f9-8327-b4c279f5bf7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def highlight_changes(original, modified):\n",
    "    \"\"\"Compares original and modified text and marks changes.\"\"\"\n",
    "    original_lines = original.split(\"\\n\")\n",
    "    modified_lines = modified.split(\"\\n\")\n",
    "\n",
    "    diff = difflib.ndiff(original_lines, modified_lines)\n",
    "    highlighted = []\n",
    "    \n",
    "    for line in diff:\n",
    "        if line.startswith(\"+ \"):  # Added text\n",
    "            highlighted.append(f\"[MODIFIED] {line[2:]}\")\n",
    "        elif line.startswith(\"- \"):  # Removed text\n",
    "            highlighted.append(f\"[REMOVED] {line[2:]}\")\n",
    "        else:\n",
    "            highlighted.append(line[2:])  \n",
    "    \n",
    "    return \"\\n\".join(highlighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "286c95fd-9e4f-44e8-9c54-9fa4de196c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_clean_text(perturbed_text):\n",
    "    \"\"\"\n",
    "    Removes [MODIFIED], [REMOVED] tags and explanations, leaving only the modified version.\n",
    "    \"\"\"\n",
    "    # Remove any [MODIFIED] or [REMOVED] markers\n",
    "    clean_text = re.sub(r\"\\[MODIFIED\\]|\\[REMOVED\\]\", \"\", perturbed_text)\n",
    "    \n",
    "    # Remove explanations (assuming they are after a certain marker like \"Explanation:\")\n",
    "    clean_text = re.sub(r\"Explanation:.*\", \"\", clean_text, flags=re.DOTALL)\n",
    "    \n",
    "    # Clean up extra spaces that may remain after removal\n",
    "    clean_text = re.sub(r\"\\n\\s*\\n\", \"\\n\", clean_text).strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6714505-9b24-4257-9275-e3d8a844533d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_perturbations(folder_path, perturbation_type=\"contradiction\"):\n",
    "    legal_docs = read_legal_files(folder_path)\n",
    "    results = []\n",
    "\n",
    "    for i, (file_name, content) in enumerate(legal_docs.items()):\n",
    "        if i >= 3:  # Stop after processing 5 documents\n",
    "            break\n",
    "        print(f\"Processing {file_name}...\")\n",
    "        perturbed_json = generate_perturbation(content, file_name, perturbation_type)\n",
    "        \n",
    "        clean_json_text = re.sub(r\"```json|```\", \"\", perturbed_json).strip()\n",
    "\n",
    "        # print('this is json:', clean_json_text)\n",
    "        try:\n",
    "            # Convert response into a Python dictionary\n",
    "            perturbed_data = json.loads(clean_json_text)\n",
    "            results.append(perturbed_data)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing JSON for {file_name}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "            \n",
    "    # Save the modified text\n",
    "    folder_path = \"perturbed_full_contract_pdf/Part_I/Affiliate_Agreements/\"\n",
    "        \n",
    "    # Save the JSON output\n",
    "    json_output_path = os.path.join(folder_path, f\"perturbed_{perturbation_type}_legal_docs.json\")\n",
    "    with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"All perturbations saved in {folder_path}\")\n",
    "\n",
    "    return perturbed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35460d2e-a980-4e0c-9807-1b046f757178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unsupported file: perturbed_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf.txt\n",
      "Skipping unsupported file: .ipynb_checkpoints\n",
      "Processing UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf...\n",
      "Processing DigitalCinemaDestinationsCorp_20111220_S-1_EX-10.10_7346719_EX-10.10_Affiliate Agreement.pdf...\n",
      "Error parsing JSON for DigitalCinemaDestinationsCorp_20111220_S-1_EX-10.10_7346719_EX-10.10_Affiliate Agreement.pdf, skipping...\n",
      "Processing LinkPlusCorp_20050802_8-K_EX-10_3240252_EX-10_Affiliate Agreement.pdf...\n",
      "All perturbations saved in perturbed_full_contract_pdf/Part_I/Affiliate_Agreements/\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"full_contract_pdf/Part_I/Affiliate_Agreements/\"\n",
    "perturbation_type = \"contradiction\"  # Change to \"ambiguity\", \"omission\", etc.\n",
    "perturbed_legal_docs = apply_perturbations(folder_path, perturbation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd77d51a-a3e6-4df7-8578-6aac8326a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_text = \"\"\"{\n",
    "    \"text\": \"hello\",\n",
    "    \"explain\": [\n",
    "        {\n",
    "            \"from\": \"tucson\"\n",
    "        }\n",
    "    ]\n",
    "}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29ad351b-3d00-44eb-9d28-4519751db166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'hello', 'explain': [{'from': 'tucson'}]}\n"
     ]
    }
   ],
   "source": [
    "json_output = json.loads(json_text)  # Converts to JSON with formatting\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76eda4ce-08c4-4ed3-90d8-4c8b621d6833",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<module 'json' from '/Users/adithmouli/anaconda3/lib/python3.11/json/__init__.py'>]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a861dbc-fca6-4d06-b681-d5fff8defa58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}