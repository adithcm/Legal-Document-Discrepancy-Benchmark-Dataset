{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4600902a-0b14-4665-affe-1501d28de4b4",
   "metadata": {},
   "source": [
    "# Initialization and Set Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b45c6acc-8851-4b17-ba0c-2ae651c039f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-generativeai in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (0.8.4)\n",
      "Requirement already satisfied: tqdm in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: google-api-python-client in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.149.0)\n",
      "Requirement already satisfied: pydantic in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.10.6)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.35.0)\n",
      "Requirement already satisfied: protobuf in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (5.28.2)\n",
      "Requirement already satisfied: google-api-core in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (2.21.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.65.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymupdf in /Users/mannanxanand/Library/Python/3.9/lib/python/site-packages (1.25.4)\n",
      "Install done\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n",
    "!pip install pymupdf\n",
    "\n",
    "print(\"Install done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb7ebc-81d3-4fca-9d7a-f925c4c22585",
   "metadata": {},
   "source": [
    "## Test Gemini API Key\n",
    "- gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf2eed28-2c34-4c62-80e2-68db59684a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "566465eb-3e09-45f0-bda0-b4892fa05e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBTYgTD42xCABfJy1jsHchkZEhFaw8X1_c\"\n",
    "# 1. AIzaSyCVjSqp_8WwJMVaIi3dVSQDRic5I1869kE\n",
    "# 2. AIzaSyCKtZRj1pJMu1JVO7siNYcqG15oTgPSj3k\n",
    "# 3. AIzaSyAjby-dj9aBsolOdTDpvU7_x5uje8l4yiQ\n",
    "# 4. AIzaSyAGHtD2RAI1geToBsVjk-mIzVeuhlZQtA4 (Noel_)\n",
    "# 5. AIzaSyBTYgTD42xCABfJy1jsHchkZEhFaw8X1_c (Mannan_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7eaec7b-a947-4309-b7be-ffc043275059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Initialize the Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58c3950b-60ba-4de2-b5f7-9f3ef344a7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine a light switch. A regular computer bit is like a light switch: it can be either ON (representing 1) or OFF (representing 0).  It's one or the other, definite and clear.\n",
      "\n",
      "Quantum computing uses **qubits**.  Think of a dimmer switch, not a regular light switch.  A qubit can be ON (1), OFF (0), or *somewhere in between*, like a blurry mix of both states simultaneously. This \"in-between\" state is called **superposition**.\n",
      "\n",
      "Think of it this way:\n",
      "\n",
      "*   **Regular Bit:**  Like flipping a coin - it's either heads or tails.\n",
      "*   **Qubit:** Like spinning a coin in the air.  It's *both* heads *and* tails until it lands.\n",
      "\n",
      "Because of this \"both at once\" ability, a qubit can explore many possibilities simultaneously, instead of one at a time like a regular bit.\n",
      "\n",
      "Here's the magic:\n",
      "\n",
      "*   **Superposition:**  Being in multiple states at the same time.\n",
      "*   **Entanglement:**  Linking two qubits together so they're connected.  If you change the state of one, you instantly know the state of the other, even if they're far apart. Think of it as two of our spinning coins suddenly linked and always landing on the same side.\n",
      "\n",
      "**So, what's the big deal?**\n",
      "\n",
      "By using superposition and entanglement, quantum computers can:\n",
      "\n",
      "*   Solve certain problems *much* faster than regular computers.  Imagine trying to find the exit in a maze. A regular computer might try each path one at a time. A quantum computer could explore all paths simultaneously, finding the exit much quicker.\n",
      "\n",
      "**What kind of problems?**\n",
      "\n",
      "*   **Drug discovery:** Simulating molecules to find new medicines.\n",
      "*   **Materials science:** Designing new and improved materials.\n",
      "*   **Cryptography:** Breaking and creating complex codes.\n",
      "*   **Financial modeling:**  Making better predictions and managing risk.\n",
      "*   **Optimization:** Finding the best solutions to complex problems, like logistics and scheduling.\n",
      "\n",
      "**In summary:**\n",
      "\n",
      "Quantum computers use qubits that can be in multiple states at once, allowing them to solve complex problems that are impossible for regular computers to handle in a reasonable amount of time.  They are not meant to replace your laptop, but rather to tackle very specific and challenging problems where their unique capabilities shine. It's still an emerging field, but it has the potential to revolutionize many areas of science and technology.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "response = model.generate_content(\"Explain quantum computing in simple terms.\")\n",
    "\n",
    "# Print the response\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b350490-c432-4f4e-a9df-930d2ac7d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import difflib\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8e98f-20dd-4490-9973-af3aa0bd3f11",
   "metadata": {},
   "source": [
    "### Error log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20c0ee2e-c784-408b-a1a0-623a81eec84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let it be global\n",
    "error_log = \"\"\"Error log\\n\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b971bd2-b223-4aed-8cca-04be4b644a04",
   "metadata": {},
   "source": [
    "# Starting of pipeline \n",
    "1. reads legal documents\n",
    "2. calls LLM to add perturbations\n",
    "3. creates output in json format\n",
    "4. stores output files in benchmark dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688473a-00a2-4601-8db2-6faee2044a65",
   "metadata": {},
   "source": [
    "## Change source folder and destination folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b104df9-c9b0-475b-9f18-b032daf453c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prompts'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edit these as needed\n",
    "\n",
    "# Folder paths\n",
    "\"\"\"\n",
    "folder_path_read = folder path to read the pdfs, put the root folder here and it picks out all pdfs\n",
    "\n",
    "folder_path_json = folder path to save the perturbation json files\n",
    "\n",
    "folder_path_save = folder path to save the modified perturbed text files\n",
    "\"\"\"\n",
    "\n",
    "folder_path_read = \"full_contract_pdf/Part_I/Endorsement/\"\n",
    "\n",
    "folder_path_json = \"benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/\"\n",
    "\n",
    "folder_path_save = \"benchmark_dataset_v1/misaligned_terminology_inText_contradication/\"\n",
    "\n",
    "# Error log file name\n",
    "error_log_name = \"error_log_misaligned_terminology_inText.txt\"\n",
    "\n",
    "# Change this as needed\n",
    "#start_folder = \"\"\n",
    "# start_folder = \"full_contract_pdf/Part_I/License_Agreements/\"\n",
    "\n",
    "# Index of subfolder to start with from the root folder in folder_path_read\n",
    "start_index = 0\n",
    "\n",
    "\"\"\"Prompts\"\"\"\n",
    "# See function generate_perturbation_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464c0a0-8258-474a-8b76-59413b99c711",
   "metadata": {},
   "source": [
    "## Retrieve content for each legal document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29c74ebe-3027-45ea-bb36-d31feadab32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_folders(root_folder, skip_folder=\".ipynb_checkpoints\"):\n",
    "    end_folders = []\n",
    "\n",
    "    for dirpath, dirnames, _ in os.walk(root_folder, topdown=True):\n",
    "        # Remove the folders that should be skipped\n",
    "        dirnames[:] = [d for d in dirnames if d != skip_folder]\n",
    "\n",
    "        # If there are no subdirectories left, it's an end folder\n",
    "        if not dirnames:\n",
    "            end_folders.append(os.path.join(dirpath, \"\"))  # Ensure trailing backslash\n",
    "\n",
    "    return end_folders\n",
    "\n",
    "# Example usage:\n",
    "# result = get_end_folders(\"full_contract_pdf\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e95c633-c782-4c90-97d1-29dd6946e6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_pdf(file_path):\n",
    "    \"\"\"Reads a PDF file\"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    return \"\\n\".join([page.get_text() for page in doc])\n",
    "\n",
    "def read_legal_files(folder_path):\n",
    "    \"\"\"Reads all legal files in the folder and returns a dictionary with file names and content.\"\"\"\n",
    "    legal_documents = {}\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            legal_documents[file_name] = read_pdf(file_path)\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file: {file_name}\")\n",
    "\n",
    "    return legal_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ead8104f-9d9e-436d-a7fc-99412b4b8da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ScansourceInc_20190822_10-K_EX-10.38_11793958_EX-10.38_Distributor Agreement1.pdf ---\n",
      "Exhibit 10.38\n",
      "IN ACCORDANCE WITH ITEM 601(b) OF REGULATION S-K, CERTAIN IDENTIFIED INFORMATION (THE “CONFIDENTIAL\n",
      "INFORMATION”) HAS BEEN EXCLUDED FROM THIS EXHIBIT BECAUSE IT IS BOTH (I) NOT MATERIAL AND (II) WOULD LIKELY\n",
      "CAUSE COMPETITIVE HARM IF PUBLICLY DISCLOSED. THE CONFIDENTIAL INFORMATION IS DENOTED HEREIN BY [*****].\n",
      "CISCO SYSTEMS, INC.\n",
      "NONEXCLUSIVE VALUE ADDED DISTRIBUTOR AGREEMENT\n",
      "This Nonexclusive Value Added Distributor Agreement (\"Agreement\"), between ScanSource, Inc., a South Carol...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read legal files\n",
    "legal_docs = read_legal_files(folder_path_read)\n",
    "\n",
    "# Display first document\n",
    "for file_name, content in legal_docs.items():\n",
    "    print(f\"--- {file_name} ---\\n{content[:500]}...\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "234a0642-e619-4b38-8722-c1c22bd8f75b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files from full_contract_pdf/Part_I/Distributor/: 13\n",
      "--- ScansourceInc_20190822_10-K_EX-10.38_11793958_EX-10.38_Distributor Agreement1.pdf ---...\n",
      "\n",
      "--- ScansourceInc_20190822_10-K_EX-10.38_11793958_EX-10.38_Distributor Agreement2.pdf ---...\n",
      "\n",
      "--- ZogenixInc_20190509_10-Q_EX-10.2_11663313_EX-10.2_Distributor Agreement.pdf ---...\n",
      "\n",
      "--- PrecheckHealthServicesInc_20200320_8-K_EX-99.2_12070169_EX-99.2_Distributor Agreement.pdf ---...\n",
      "\n",
      "--- FuseMedicalInc_20190321_10-K_EX-10.43_11575454_EX-10.43_Distributor Agreement.pdf ---...\n",
      "\n",
      "--- ScansourceInc_20190822_10-K_EX-10.39_11793959_EX-10.39_Distributor Agreement.pdf ---...\n",
      "\n",
      "--- WaterNowInc_20191120_10-Q_EX-10.12_11900227_EX-10.12_Distributor Agreement.pdf ---...\n",
      "\n",
      "--- ScansourceInc_20190509_10-Q_EX-10.2_11661422_EX-10.2_Distributor Agreement.pdf ---...\n",
      "\n",
      "--- SmartRxSystemsInc_20180914_1-A_EX1A-6 MAT CTRCT_11351705_EX1A-6 MAT CTRCT_Distributor Agreement.pdf ---...\n",
      "\n",
      "--- InnerscopeHearingTechnologiesInc_20181109_8-K_EX-10.6_11419704_EX-10.6_Distributor Agreement.pdf ---...\n",
      "\n",
      "--- ImineCorp_20180725_S-1_EX-10.5_11275970_EX-10.5_Distributor Agreement.pdf ---...\n",
      "\n",
      "--- GentechHoldingsInc_20190808_1-A_EX1A-6 MAT CTRCT_11776814_EX1A-6 MAT CTRCT_Distributor Agreement.pdf ---...\n",
      "\n",
      "--- StaarSurgicalCompany_20180801_10-Q_EX-10.37_11289449_EX-10.37_Distributor Agreement.pdf ---...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing all file names that were accepted\n",
    "print(f\"Total files from {folder_path_read}: {len(legal_docs)}\") \n",
    "for file_name, content in legal_docs.items():\n",
    "    print(f\"--- {file_name} ---...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e690d5e9-9048-4b8b-ba58-f38a688c7e8b",
   "metadata": {},
   "source": [
    "## Prompt to read through legal file and insert different types of perturbations\n",
    "- 10 different types of prompts to switch\n",
    "- returns output in json format, which would be considered as lock-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "914eea60-d941-4935-b48a-8debaddabfc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_perturbation_new(original_text, file_name, prompt):    \n",
    "    \"\"\"Generates a perturbed version of the legal document section in structured JSON format.\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"You are a contract drafting consultant ensuring that legal agreements use consistent terminology. Your task is to modify a contract by using different terms interchangeably, creating an internal contradiction.\n",
    "\n",
    "    ### **Definition:**\n",
    "    Misaligned terminology also leads to **in-text contradictions** when the contract **uses multiple terms interchangeably without defining them**, leading to conflicting obligations.\n",
    "    \n",
    "    ### **Step-by-Step Instructions:**\n",
    "    1. Identify a **key term** in the contract.\n",
    "    2. Modify its definition in different sections so that they **conflict**.\n",
    "    3. Ensure the contradiction creates **uncertainty in enforcement**.\n",
    "    4. For that perturbation, make sure in the file there should be **2-3** of them. \n",
    "    5. Output the modified contract in structured JSON format.\n",
    "    6. Make sure that when taking the original texts, there should be no jumps between sentences. Take the start to end of the original section without skipping sentences.\n",
    "    \n",
    "    -----\n",
    "    \n",
    "    ### **Examples of Different Terminology for the Same Concept:**\n",
    "    \n",
    "    **Example 1:**\n",
    "    - **Section 1:** \"The Vendor shall supply goods within 30 days.\"\n",
    "    - **Section 7:** \"The Supplier shall ensure delivery within 60 days.\"\n",
    "    - **Explanation:** It’s unclear whether **“Vendor” and “Supplier”** refer to the same entity, leading to conflicting delivery terms.\n",
    "    \n",
    "    **Example 2:**\n",
    "    - **Section 2:** \"The Client is responsible for compliance with all data privacy laws.\"\n",
    "    - **Section 10:** \"The Customer must ensure compliance with all data regulations.\"\n",
    "    - **Explanation:** It’s unclear whether **“Client” and “Customer”** are interchangeable.\n",
    "    \n",
    "    **Example 3:**\n",
    "    - **Section 3:** \"Security breaches must be reported to the Compliance Officer.\"\n",
    "    - **Section 12:** \"Data incidents must be escalated to the Security Team.\"\n",
    "    - **Explanation:** The document fails to define whether **“security breaches” and “data incidents”** are the same.\n",
    "    \n",
    "    **Example 4:**\n",
    "    - **Section 4:** \"Employees must follow the HR Manual for grievance resolution.\"\n",
    "    - **Section 9:** \"Personnel must refer to the Workplace Handbook for grievance handling.\"\n",
    "    - **Explanation:** **“HR Manual” and “Workplace Handbook”** are undefined—this could cause **disputes over policies**.\n",
    "    \n",
    "    **Example 5:**\n",
    "    - **Section 7:** \"The seller warrants that all goods are defect-free.\"\n",
    "    - **Section 15:** \"The distributor ensures that all products meet quality standards.\"\n",
    "    - **Explanation:** **“Seller” and “Distributor”** may not be the same entity, leading to **liability confusion**.\n",
    "    \n",
    "    **Example 6:**\n",
    "    - **Original:** \"The employee shall be entitled to overtime pay for any hours worked beyond 40 hours per week, calculated at 1.5 times the regular hourly rate. Overtime pay shall be included in the next payroll cycle and must be properly documented.\"\n",
    "    - **Modified:** \"The employee may receive additional compensation for any hours worked beyond the normal workweek, subject to company policy.\"\n",
    "    - **Explanation:** The original text enforces **overtime pay as a legal right**, whereas the modified version replaces **'overtime pay'** with **'additional compensation'** and makes it subject to 'company policy.' This contradicts **labor laws (FLSA)**, which mandate **overtime pay at 1.5x the hourly rate**.\n",
    "    ---\n",
    "    \n",
    "    ### **Return JSON Format**\n",
    "    {{\n",
    "        \"file_name\": {file_name},\n",
    "        \"perturbation\": [\n",
    "            {{\n",
    "                \"type\": \"Misaligned Terminology - In Text Contradiction\",\n",
    "                \"original_text\": \"EXCERPT BEFORE CHANGE\",\n",
    "                \"changed_text\": \"EXCERPT AFTER CHANGE\",\n",
    "                \"explanation\": \"WHY THIS CHANGE INTRODUCES A PERTURBATION\",\n",
    "                \"location\": \"SECTION OR PARAGRAPH NUMBER\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    \n",
    "    Below is the original legal text:\n",
    "    -------------------\n",
    "    {original_text}\n",
    "    -------------------\n",
    "    \n",
    "    Now, return ONLY the structured JSON object with the modified text and explanation.\n",
    "    \"\"\"\n",
    "    \n",
    "    global error_log\n",
    "    response = None\n",
    "    response_text = None\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        response_text = response.text\n",
    "    except ValueError as e:\n",
    "        if \"reciting from copyrighted material\" in str(e):\n",
    "            print(\"Error: The model was reciting from copyrighted material. Please modify your prompt.\")\n",
    "        error_log += f\"\"\"\\nIn {file_name}: \n",
    "        Error name: ValueError\n",
    "        Error message: {e}\\n\"\"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        error_log += f\"\"\"\\nIn {file_name}: \n",
    "        Error name: Exception\n",
    "        Error message: {e}\\n\"\"\"\n",
    "\n",
    "    \n",
    "    return response_text if response else \"ERROR: No response from API\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2ab12e-4c94-4279-b409-6a81a5360f78",
   "metadata": {},
   "source": [
    "## Applies perturbations to files and stores in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6714505-9b24-4257-9275-e3d8a844533d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_perturbations(folder_path_read, folder_path_json, folder_path_save, prompt):\n",
    "    legal_docs = read_legal_files(folder_path_read)\n",
    "\n",
    "    global error_log\n",
    "\n",
    "    for i, (file_name, content) in enumerate(legal_docs.items()):\n",
    "        print(\"________________________________________________________________________\")\n",
    "        results = []\n",
    "        # if i >= 10:  # Stop after processing 5 documents\n",
    "        #      break\n",
    "        print(f\"Processing {file_name}...\")\n",
    "        #perturbed_json = generate_perturbation(content, file_name, perturbation_type)\n",
    "        perturbed_json = generate_perturbation_new(content, file_name, prompt)\n",
    "\n",
    "        # If there is no returned json, return this message\n",
    "        if perturbed_json.__eq__(\"ERROR: No response from API\"):\n",
    "            continue\n",
    "        \n",
    "        #print(\"This is the perturbed json:\", perturbed_json)\n",
    "        clean_json_text = re.sub(r\"```json|```\", \"\", perturbed_json).strip()\n",
    "\n",
    "        # print('this is json:', clean_json_text)\n",
    "        try:\n",
    "            # Convert response into a Python dictionary\n",
    "            perturbed_data = json.loads(clean_json_text)\n",
    "            results.append(perturbed_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON for {file_name}, writing into logs and skipping...\")\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: JSONDecodeError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            continue\n",
    "            \n",
    "        # Save the JSON output\n",
    "        json_output_path = os.path.join(folder_path_json, f\"perturbed_{file_name}.json\")\n",
    "        json_output_path = json_output_path.strip()\n",
    "        try:\n",
    "            with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"An error occurred while writing to the file: {e}\")\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: FileNotFoundError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            continue\n",
    "        except IOError as e:\n",
    "            print(f\"An error occurred while writing to the file: {e}\")\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: IOError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            continue\n",
    "        except json.JSONEncodeError as e:\n",
    "            print(f\"An error occurred while encoding JSON: {e}\")\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: JSONEncodeError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # Apply the perturbation from json to text\n",
    "        modified_contract = apply_perturbation_from_json(content, json_output_path, folder_path_save)\n",
    "\n",
    "        # Write to a log file for this folder\n",
    "    \n",
    "    print(f\"All perturbations saved in {folder_path_save}\")\n",
    "\n",
    "    return perturbed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b5aaf19-f025-4db5-9757-1750717fc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalizes text by removing extra spaces, line breaks, and ensuring consistent spacing. Helper function.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")  # Replace newlines with space\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Replace multiple spaces with a single space\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fbac08-c4a0-4f57-9369-1af2ca060ec0",
   "metadata": {},
   "source": [
    "## Create and store tagged modified file from its respective json log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16865e3c-53dc-4ea5-bf3d-27ca5913218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perturbation_from_json(original_text, json_file, output_folder=\"test_benchmark_dataset/\"):\n",
    "    \"\"\"\n",
    "    Reads the JSON metadata and applies the described perturbations to the original document,\n",
    "    adding unique <*$p$*> markers around the modified sections.\n",
    "\n",
    "    Parameters:\n",
    "    - original_text (str): The original contract text.\n",
    "    - json_file (str): Path to the JSON file containing the perturbation details.\n",
    "    - output_folder (str): Folder to save the modified contract.\n",
    "\n",
    "    Returns:\n",
    "    - modified_text (str): The full modified document.\n",
    "    \"\"\"\n",
    "\n",
    "    global error_log\n",
    "    # Ensure the output directory exists\n",
    "    #os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(json_file):  # Check if the file does NOT exist\n",
    "        print(f\"File '{json_file}' does not exist. Skipping execution.\")\n",
    "        return null\n",
    "    \n",
    "    print(\"json file:\", json_file)\n",
    "    \n",
    "    # Load the JSON metadata\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    #print(\"File successfully loaded\") \n",
    "    if isinstance(json_data, list) and len(json_data) > 0:\n",
    "        json_data = json_data[0]  # Extract the first item in the list\n",
    "    \n",
    "    # Normalize the original contract text\n",
    "    normalized_text = normalize_text(original_text)\n",
    "    normalized_text = normalize_text(original_text)\n",
    "    if not normalized_text:\n",
    "        print(\"Warning: The original text is empty. Skipping file.\")\n",
    "        return \"EMPTY CONTENT\"\n",
    "\n",
    "\n",
    "    # Apply modifications with unique markers\n",
    "    modified_text = normalized_text\n",
    "    \n",
    "    for perturbation in json_data[\"perturbation\"]:\n",
    "        # Normalize both original and the changed section of text\n",
    "        original_section = normalize_text(perturbation[\"original_text\"])  \n",
    "        #print(\"this is original text:\", original_section)\n",
    "        changed_section = normalize_text(perturbation[\"changed_text\"])\n",
    "        #print(\"this is the changed text:\", changed_section)\n",
    "        \n",
    "        # Wrap changed section with unique <*$p$*> markers\n",
    "        marked_section = f\"<*$p$*>{changed_section}<*$p$*>\"\n",
    "\n",
    "        # Replace original section with marked modified section\n",
    "        if original_section in modified_text:\n",
    "            modified_text = modified_text.replace(original_section, marked_section)\n",
    "        else:\n",
    "            e = f\"Could not find section in text: {original_section}\"\n",
    "            print(\"Warning: \" + e)\n",
    "            error_log += f\"\"\"\\nIn {file_name}: \n",
    "            Error name: FileModifyError\n",
    "            Error message: {e}\\n\"\"\"\n",
    "            error = \"COULD NOT MODIFY FILE\"\n",
    "            return error\n",
    "\n",
    "    print(\"File modified, saving...\")\n",
    "    # Save the modified contract as a new file\n",
    "    modified_file_name = f\"modified_{json_data['file_name']}.txt\"\n",
    "    modified_file_path = os.path.join(output_folder, modified_file_name)\n",
    "\n",
    "    with open(modified_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(modified_text)\n",
    "\n",
    "    print(f\"File '{json_file}' loaded and written.\") \n",
    "    return modified_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c045b-ea52-47e7-8ac0-13c588c7c1c2",
   "metadata": {},
   "source": [
    "## Functions to clean and apply highlighting to the perturbed legal documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a79ab53-273a-4dd7-aefd-ec3dd653509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_changes(original, modified):\n",
    "    \"\"\"Compares original and modified text and marks changes.\"\"\"\n",
    "    original_lines = original.split(\"\\n\")\n",
    "    modified_lines = modified.split(\"\\n\")\n",
    "\n",
    "    diff = difflib.ndiff(original_lines, modified_lines)\n",
    "    highlighted = []\n",
    "    \n",
    "    for line in diff:\n",
    "        if line.startswith(\"+ \"):  # Added text\n",
    "            highlighted.append(f\"[MODIFIED] {line[2:]}\")\n",
    "        elif line.startswith(\"- \"):  # Removed text\n",
    "            highlighted.append(f\"[REMOVED] {line[2:]}\")\n",
    "        else:\n",
    "            highlighted.append(line[2:])  \n",
    "    \n",
    "    return \"\\n\".join(highlighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a01d4b9f-84cf-4f1f-8db8-ee290e88154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clean_text(perturbed_text):\n",
    "    \"\"\"\n",
    "    Removes [MODIFIED], [REMOVED] tags and explanations, leaving only the modified version.\n",
    "    \"\"\"\n",
    "    # Remove any [MODIFIED] or [REMOVED] markers\n",
    "    clean_text = re.sub(r\"\\[MODIFIED\\]|\\[REMOVED\\]\", \"\", perturbed_text)\n",
    "    \n",
    "    # Remove explanations (assuming they are after a certain marker like \"Explanation:\")\n",
    "    clean_text = re.sub(r\"Explanation:.*\", \"\", clean_text, flags=re.DOTALL)\n",
    "    \n",
    "    # Clean up extra spaces that may remain after removal\n",
    "    clean_text = re.sub(r\"\\n\\s*\\n\", \"\\n\", clean_text).strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35460d2e-a980-4e0c-9807-1b046f757178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Currently in full_contract_pdf/Part_I/Distributor/\n",
      "\n",
      "________________________________________________________________________\n",
      "Processing ScansourceInc_20190822_10-K_EX-10.38_11793958_EX-10.38_Distributor Agreement1.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_ScansourceInc_20190822_10-K_EX-10.38_11793958_EX-10.38_Distributor Agreement1.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_ScansourceInc_20190822_10-K_EX-10.38_11793958_EX-10.38_Distributor Agreement1.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing ScansourceInc_20190822_10-K_EX-10.38_11793958_EX-10.38_Distributor Agreement2.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_ScansourceInc_20190822_10-K_EX-10.38_11793958_EX-10.38_Distributor Agreement2.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_ScansourceInc_20190822_10-K_EX-10.38_11793958_EX-10.38_Distributor Agreement2.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing ZogenixInc_20190509_10-Q_EX-10.2_11663313_EX-10.2_Distributor Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_ZogenixInc_20190509_10-Q_EX-10.2_11663313_EX-10.2_Distributor Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_ZogenixInc_20190509_10-Q_EX-10.2_11663313_EX-10.2_Distributor Agreement.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing PrecheckHealthServicesInc_20200320_8-K_EX-99.2_12070169_EX-99.2_Distributor Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_PrecheckHealthServicesInc_20200320_8-K_EX-99.2_12070169_EX-99.2_Distributor Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_PrecheckHealthServicesInc_20200320_8-K_EX-99.2_12070169_EX-99.2_Distributor Agreement.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing FuseMedicalInc_20190321_10-K_EX-10.43_11575454_EX-10.43_Distributor Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_FuseMedicalInc_20190321_10-K_EX-10.43_11575454_EX-10.43_Distributor Agreement.pdf.json\n",
      "Warning: Could not find section in text: 4. Supply of products 4.1 The parties acknowledge that: (a) the Supplier is the manufacturer of the Products; and (b) the Supplier will have no obligation to separately supply the Products, except as otherwise provided for in this Agreement.\n",
      "________________________________________________________________________\n",
      "Processing ScansourceInc_20190822_10-K_EX-10.39_11793959_EX-10.39_Distributor Agreement.pdf...\n",
      "Error parsing JSON for ScansourceInc_20190822_10-K_EX-10.39_11793959_EX-10.39_Distributor Agreement.pdf, writing into logs and skipping...\n",
      "________________________________________________________________________\n",
      "Processing WaterNowInc_20191120_10-Q_EX-10.12_11900227_EX-10.12_Distributor Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_WaterNowInc_20191120_10-Q_EX-10.12_11900227_EX-10.12_Distributor Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_WaterNowInc_20191120_10-Q_EX-10.12_11900227_EX-10.12_Distributor Agreement.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing ScansourceInc_20190509_10-Q_EX-10.2_11661422_EX-10.2_Distributor Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_ScansourceInc_20190509_10-Q_EX-10.2_11661422_EX-10.2_Distributor Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_ScansourceInc_20190509_10-Q_EX-10.2_11661422_EX-10.2_Distributor Agreement.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing SmartRxSystemsInc_20180914_1-A_EX1A-6 MAT CTRCT_11351705_EX1A-6 MAT CTRCT_Distributor Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_SmartRxSystemsInc_20180914_1-A_EX1A-6 MAT CTRCT_11351705_EX1A-6 MAT CTRCT_Distributor Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_SmartRxSystemsInc_20180914_1-A_EX1A-6 MAT CTRCT_11351705_EX1A-6 MAT CTRCT_Distributor Agreement.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing InnerscopeHearingTechnologiesInc_20181109_8-K_EX-10.6_11419704_EX-10.6_Distributor Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_InnerscopeHearingTechnologiesInc_20181109_8-K_EX-10.6_11419704_EX-10.6_Distributor Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_InnerscopeHearingTechnologiesInc_20181109_8-K_EX-10.6_11419704_EX-10.6_Distributor Agreement.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing ImineCorp_20180725_S-1_EX-10.5_11275970_EX-10.5_Distributor Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_ImineCorp_20180725_S-1_EX-10.5_11275970_EX-10.5_Distributor Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_ImineCorp_20180725_S-1_EX-10.5_11275970_EX-10.5_Distributor Agreement.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing GentechHoldingsInc_20190808_1-A_EX1A-6 MAT CTRCT_11776814_EX1A-6 MAT CTRCT_Distributor Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_GentechHoldingsInc_20190808_1-A_EX1A-6 MAT CTRCT_11776814_EX1A-6 MAT CTRCT_Distributor Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_GentechHoldingsInc_20190808_1-A_EX1A-6 MAT CTRCT_11776814_EX1A-6 MAT CTRCT_Distributor Agreement.pdf.json' loaded and written.\n",
      "________________________________________________________________________\n",
      "Processing StaarSurgicalCompany_20180801_10-Q_EX-10.37_11289449_EX-10.37_Distributor Agreement.pdf...\n",
      "json file: benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_StaarSurgicalCompany_20180801_10-Q_EX-10.37_11289449_EX-10.37_Distributor Agreement.pdf.json\n",
      "File modified, saving...\n",
      "File 'benchmark_dataset_v1/misaligned_terminology_inText_contradication_json/perturbed_StaarSurgicalCompany_20180801_10-Q_EX-10.37_11289449_EX-10.37_Distributor Agreement.pdf.json' loaded and written.\n",
      "All perturbations saved in benchmark_dataset_v1/misaligned_terminology_inText_contradication/\n"
     ]
    }
   ],
   "source": [
    "# Destination directory creation and check\n",
    "os.makedirs(folder_path_json, exist_ok=True)\n",
    "os.makedirs(folder_path_save, exist_ok=True)\n",
    "\n",
    "# Get all end folders, make it quick\n",
    "end_folder_names = get_end_folders(folder_path_read)\n",
    "# perturbation_type = \"contradiction\"  # Change to \"ambiguity\", \"omission\", etc.\n",
    "# perturbed_legal_docs = apply_perturbations(folder_path_read, folder_path_json, folder_path_save, perturbation_type, prompt)\n",
    "\n",
    "# Find the index of the start folder\n",
    "# if start_folder in end_folder_names:\n",
    "#     start_index = end_folder_names.index(start_folder)\n",
    "# else:\n",
    "#     start_index = 0  # Default to starting from the beginning if folder not found\n",
    "\n",
    "# Initialize perturbed_json outside the loop to avoid UnboundLocalError\n",
    "perturbed_json = \"No perturbations applied\"\n",
    "\n",
    "for folder_name in end_folder_names[start_index:]:\n",
    "    print(\"\\nCurrently in \" + folder_name + \"\\n\")\n",
    "    perturbed_legal_docs = apply_perturbations(folder_name, folder_path_json, folder_path_save, \"\")\n",
    "    if perturbed_legal_docs:\n",
    "        perturbed_json = perturbed_legal_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566b468-b618-4329-99cf-afaeb859f7eb",
   "metadata": {},
   "source": [
    "# End of Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ecd68eec-73ef-4eb8-98c9-464592939f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error log written successfully.\n"
     ]
    }
   ],
   "source": [
    "# Output error log txt file\n",
    "# print(error_log)\n",
    "with open(error_log_name, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(error_log)\n",
    "\n",
    "print(\"Error log written successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a861dbc-fca6-4d06-b681-d5fff8defa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOP\n"
     ]
    }
   ],
   "source": [
    "print(\"EOP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
