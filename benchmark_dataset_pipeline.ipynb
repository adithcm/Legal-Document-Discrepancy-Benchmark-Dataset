{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4600902a-0b14-4665-affe-1501d28de4b4",
   "metadata": {},
   "source": [
    "# Initialization and Set Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45c6acc-8851-4b17-ba0c-2ae651c039f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\user\\anaconda3\\lib\\site-packages (0.8.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (2.165.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (2.5.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\user\\anaconda3\\lib\\site-packages (1.25.4)\n",
      "Install done\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n",
    "!pip install pymupdf\n",
    "\n",
    "print(\"Install done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb7ebc-81d3-4fca-9d7a-f925c4c22585",
   "metadata": {},
   "source": [
    "## Test Gemini API Key\n",
    "- gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf2eed28-2c34-4c62-80e2-68db59684a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566465eb-3e09-45f0-bda0-b4892fa05e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCVjSqp_8WwJMVaIi3dVSQDRic5I1869kE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7eaec7b-a947-4309-b7be-ffc043275059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Initialize the Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58c3950b-60ba-4de2-b5f7-9f3ef344a7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "response = model.generate_content(\"Explain quantum computing in simple terms.\")\n",
    "\n",
    "# Print the response\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b350490-c432-4f4e-a9df-930d2ac7d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import difflib\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b971bd2-b223-4aed-8cca-04be4b644a04",
   "metadata": {},
   "source": [
    "# Starting of pipeline \n",
    "1. reads legal documents\n",
    "2. calls LLM to add perturbations\n",
    "3. creates output in json format\n",
    "4. stores output files in benchmark dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688473a-00a2-4601-8db2-6faee2044a65",
   "metadata": {},
   "source": [
    "## Change source folder and destination folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8b104df9-c9b0-475b-9f18-b032daf453c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit these as needed\n",
    "\"\"\"Folder paths\"\"\"\n",
    "folder_path_read = \"full_contract_pdf/Part_I/Affiliate_Agreements/\"\n",
    "\n",
    "folder_path_json = \"test_benchmark_dataset/ambiguity_legal_contradication_json/\"\n",
    "\n",
    "folder_path_save = \"test_benchmark_dataset/ambiguity_legal_contradication/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464c0a0-8258-474a-8b76-59413b99c711",
   "metadata": {},
   "source": [
    "## Retrieve content for each legal document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5e95c633-c782-4c90-97d1-29dd6946e6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_pdf(file_path):\n",
    "    \"\"\"Reads a PDF file\"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    return \"\\n\".join([page.get_text() for page in doc])\n",
    "\n",
    "def read_legal_files(folder_path):\n",
    "    \"\"\"Reads all legal files in the folder and returns a dictionary with file names and content.\"\"\"\n",
    "    legal_documents = {}\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            legal_documents[file_name] = read_pdf(file_path)\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file: {file_name}\")\n",
    "\n",
    "    return legal_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ead8104f-9d9e-436d-a7fc-99412b4b8da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unsupported file: .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Read legal files\n",
    "legal_docs = read_legal_files(folder_path_read)\n",
    "\n",
    "# Display first document\n",
    "# for file_name, content in legal_docs.items():\n",
    "#     print(f\"--- {file_name} ---\\n{content[:500]}...\\n\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "234a0642-e619-4b38-8722-c1c22bd8f75b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files from full_contract_pdf/Part_I/Affiliate_Agreements/: 9\n",
      "--- CreditcardscomInc_20070810_S-1_EX-10.33_362297_EX-10.33_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605784_EX-10.27_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- DigitalCinemaDestinationsCorp_20111220_S-1_EX-10.10_7346719_EX-10.10_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- LinkPlusCorp_20050802_8-K_EX-10_3240252_EX-10_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- SouthernStarEnergyInc_20051202_SB-2A_EX-9_801890_EX-9_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- SteelVaultCorp_20081224_10-K_EX-10.16_3074935_EX-10.16_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- TubeMediaCorp_20060310_8-K_EX-10.1_513921_EX-10.1_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- UnionDentalHoldingsInc_20050204_8-KA_EX-10_3345577_EX-10_Affiliate Agreement.pdf ---...\n",
      "\n",
      "--- UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf ---...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing all file names that were accepted\n",
    "print(f\"Total files from {folder_path_read}: {len(legal_docs)}\") \n",
    "for file_name, content in legal_docs.items():\n",
    "    print(f\"--- {file_name} ---...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e690d5e9-9048-4b8b-ba58-f38a688c7e8b",
   "metadata": {},
   "source": [
    "## Prompt to read through legal file and insert different types of perturbations\n",
    "- 10 different types of prompts to switch\n",
    "- returns output in json format, which would be considered as lock-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "914eea60-d941-4935-b48a-8debaddabfc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_perturbation_new(original_text, file_name):    \n",
    "    \"\"\"Generates a perturbed version of the legal document section in structured JSON format.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are a senior compliance officer reviewing a legal contract. Your task is to modify a section of the contract by introducing an ambiguous legal obligation while ensuring that the ambiguity contradicts a state or national law.\n",
    "\n",
    "    Before modifying the text:\n",
    "    - **Read the file** to determine what city, state, or country the contract applies to.\n",
    "    - If the jurisdiction is unclear, default to **United States law**.\n",
    "    - Make sure that when taking the original texts, there should be no jumps between sentences. Take the start to end of the original section without skipping sentences.\n",
    "\n",
    "    ### **Definition:**\n",
    "    Ambiguities occur when a legal statement is vague, leading to multiple interpretations. A **legal contradiction** under this category happens when an obligation is introduced ambiguously, making it difficult to enforce under state or national law. This can result in non-compliance with regulatory requirements, leaving legal obligations open to dispute.\n",
    "\n",
    "    ### **Step-by-Step Instructions:**\n",
    "    1. Identify a clear legal obligation in the contract.\n",
    "    2. Modify the wording to make it **vague or open to multiple interpretations**.\n",
    "    3. Ensure that this ambiguity creates **non-compliance with a specific law** in the identified jurisdiction.\n",
    "    4. For that perturbation, make sure in the file there should be **2-3** of them. \n",
    "    5. Output the modified contract in structured JSON format.\n",
    "\n",
    "    ---\n",
    "\n",
    "    ### **Examples of Ambiguous Legal Obligations:**\n",
    "\n",
    "    **Example 1:**\n",
    "    - **Original:** \"The company shall provide necessary accommodations for disabled employees.\"\n",
    "    - **Modified:** \"The company shall provide accommodations for disabled employees as deemed appropriate.\"\n",
    "    - **Explanation:** The term \"as deemed appropriate\" introduces ambiguity, conflicting with **ADA (Americans with Disabilities Act)**, which mandates **clear, non-discretionary accommodations**.\n",
    "\n",
    "    **Example 2:**\n",
    "    - **Original:** \"All contractors must comply with local zoning laws.\"\n",
    "    - **Modified:** \"All contractors must make reasonable efforts to comply with zoning laws.\"\n",
    "    - **Explanation:** \"Reasonable efforts\" is vague—some zoning laws require strict adherence.\n",
    "\n",
    "    **Example 3:**\n",
    "    - **Original:** \"The landlord shall ensure habitable living conditions in compliance with state law.\"\n",
    "    - **Modified:** \"The landlord shall make efforts to maintain habitable conditions.\"\n",
    "    - **Explanation:** \"Make efforts\" does not guarantee habitability, which violates **tenant protection laws**.\n",
    "\n",
    "    **Example 4:**\n",
    "    - **Original:** \"The company shall maintain data security measures that meet industry standards.\"\n",
    "    - **Modified:** \"The company shall maintain data security measures that it deems sufficient.\"\n",
    "    - **Explanation:** \"Deems sufficient\" is subjective and contradicts **GDPR and CCPA** requirements for **specific security standards**.\n",
    "\n",
    "    **Example 5:**\n",
    "    - **Original:** \"Employees shall be provided meal breaks as required by law.\"\n",
    "    - **Modified:** \"Employees shall be encouraged to take meal breaks.\"\n",
    "    - **Explanation:** Some states require **mandatory** meal breaks (e.g., California).\n",
    "    \n",
    "    **Example 6:**\n",
    "    - **Original:** \"The Contractor shall comply with all federal and state regulations governing workplace safety, ensuring all necessary precautions are taken to protect employees from occupational hazards. The Contractor must conduct quarterly safety inspections and submit reports to regulatory authorities. Any violations of safety standards shall result in corrective actions and potential penalties. The company’s leadership is responsible for ensuring full compliance at all levels.\"\n",
    "    - **Modified:** \"The Contractor should make reasonable efforts to comply with applicable federal and state regulations governing workplace safety. The Contractor may conduct periodic safety inspections and submit reports when deemed necessary. Violations of safety standards will be assessed on a case-by-case basis, and corrective actions may be recommended where appropriate.\"\n",
    "    - **Explanation:** This change weakens the legal obligation by replacing 'shall comply' with 'should make reasonable efforts,' making compliance discretionary rather than mandatory. The removal of 'quarterly safety inspections' eliminates a clear legal requirement, and replacing 'shall result in corrective actions' with 'may be recommended' creates uncertainty. This contradicts **OSHA regulations**, which mandate strict compliance and routine reporting on workplace safety violations.\n",
    "    ---\n",
    "\n",
    "    \n",
    "    ### **Return JSON Format**\n",
    "    {{\n",
    "        \"file_name\": {file_name},\n",
    "        \"perturbation\": [\n",
    "            {{\n",
    "                \"type\": \"Ambiguities - Ambiguous Legal Obligation\",\n",
    "                \"original_text\": \"EXCERPT BEFORE CHANGE\",\n",
    "                \"changed_text\": \"EXCERPT AFTER CHANGE\",\n",
    "                \"explanation\": \"WHY THIS CHANGE INTRODUCES A PERTURBATION\",\n",
    "                \"contradicted_law\": \"SPECIFIC LAW OR REGULATION BEING VIOLATED\",\n",
    "                \"location\": \"SECTION OR PARAGRAPH NUMBER\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    \n",
    "    Below is the original legal text:\n",
    "    -------------------\n",
    "    {original_text}\n",
    "    -------------------\n",
    "\n",
    "    Now, return ONLY the structured JSON object with the modified text and explanation.\n",
    "    \"\"\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text if response else \"ERROR: No response from API\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2ab12e-4c94-4279-b409-6a81a5360f78",
   "metadata": {},
   "source": [
    "## Applies perturbations to files and stores in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d6714505-9b24-4257-9275-e3d8a844533d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_perturbations(folder_path_read, folder_path_json, folder_path_save, perturbation_type=\"contradiction\"):\n",
    "    legal_docs = read_legal_files(folder_path_read)\n",
    "    \n",
    "\n",
    "    for i, (file_name, content) in enumerate(legal_docs.items()):\n",
    "        results = []\n",
    "        # if i >= 10:  # Stop after processing 5 documents\n",
    "        #      break\n",
    "        print(f\"Processing {file_name}...\")\n",
    "        #perturbed_json = generate_perturbation(content, file_name, perturbation_type)\n",
    "        perturbed_json = generate_perturbation_new(content, file_name)\n",
    "        #print(\"This is the perturbed json:\", perturbed_json)\n",
    "        clean_json_text = re.sub(r\"```json|```\", \"\", perturbed_json).strip()\n",
    "\n",
    "        # print('this is json:', clean_json_text)\n",
    "        try:\n",
    "            # Convert response into a Python dictionary\n",
    "            perturbed_data = json.loads(clean_json_text)\n",
    "            results.append(perturbed_data)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing JSON for {file_name}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Save the JSON output\n",
    "        json_output_path = os.path.join(folder_path_json, f\"perturbed_{file_name}.json\")\n",
    "        with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        # Apply the perturbation from json to text\n",
    "        modified_contract = apply_perturbation_from_json(content, json_output_path, folder_path_save)\n",
    "        print(\"________________________________________________________________________\")\n",
    "\n",
    "    print(f\"All perturbations saved in {folder_path_save}\")\n",
    "\n",
    "    return perturbed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5b5aaf19-f025-4db5-9757-1750717fc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalizes text by removing extra spaces, line breaks, and ensuring consistent spacing. Helper function.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")  # Replace newlines with space\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Replace multiple spaces with a single space\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fbac08-c4a0-4f57-9369-1af2ca060ec0",
   "metadata": {},
   "source": [
    "## Create and store tagged modified file from its respective json log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "16865e3c-53dc-4ea5-bf3d-27ca5913218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perturbation_from_json(original_text, json_file, output_folder=\"test_benchmark_dataset/ambiguity_inText_contradiction/modified_files_tags/\"):\n",
    "    \"\"\"\n",
    "    Reads the JSON metadata and applies the described perturbations to the original document,\n",
    "    adding unique <*$p$*> markers around the modified sections.\n",
    "\n",
    "    Parameters:\n",
    "    - original_text (str): The original contract text.\n",
    "    - json_file (str): Path to the JSON file containing the perturbation details.\n",
    "    - output_folder (str): Folder to save the modified contract.\n",
    "\n",
    "    Returns:\n",
    "    - modified_text (str): The full modified document.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    print(\"json file:\", json_file)\n",
    "    \n",
    "    # Load the JSON metadata\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    print(\"File successfully loaded\") \n",
    "    if isinstance(json_data, list) and len(json_data) > 0:\n",
    "        json_data = json_data[0]  # Extract the first item in the list\n",
    "    \n",
    "    # Normalize the original contract text\n",
    "    normalized_text = normalize_text(original_text)\n",
    "\n",
    "    # Apply modifications with unique markers\n",
    "    modified_text = normalized_text\n",
    "    \n",
    "    for perturbation in json_data[\"perturbation\"]:\n",
    "        # Normalize both original and the changed section of text\n",
    "        original_section = normalize_text(perturbation[\"original_text\"])  \n",
    "        #print(\"this is original text:\", original_section)\n",
    "        changed_section = normalize_text(perturbation[\"changed_text\"])\n",
    "        #print(\"this is the changed text:\", changed_section)\n",
    "        \n",
    "        # Wrap changed section with unique <*$p$*> markers\n",
    "        marked_section = f\"<*$p$*>{changed_section}<*$p$*>\"\n",
    "\n",
    "        # Replace original section with marked modified section\n",
    "        if original_section in modified_text:\n",
    "            modified_text = modified_text.replace(original_section, marked_section)\n",
    "        else:\n",
    "            print(f\"Warning: Could not find section in text: {original_section}\")\n",
    "            error = \"COULD NOT MODIFY FILE\"\n",
    "            return error\n",
    "\n",
    "    print(\"File modified, saving...\")\n",
    "    # Save the modified contract as a new file\n",
    "    modified_file_name = f\"modified_{json_data['file_name']}.txt\"\n",
    "    modified_file_path = os.path.join(output_folder, modified_file_name)\n",
    "\n",
    "    with open(modified_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(modified_text)\n",
    "\n",
    "    return modified_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c045b-ea52-47e7-8ac0-13c588c7c1c2",
   "metadata": {},
   "source": [
    "## Functions to clean and apply highlighting to the perturbed legal documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3a79ab53-273a-4dd7-aefd-ec3dd653509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_changes(original, modified):\n",
    "    \"\"\"Compares original and modified text and marks changes.\"\"\"\n",
    "    original_lines = original.split(\"\\n\")\n",
    "    modified_lines = modified.split(\"\\n\")\n",
    "\n",
    "    diff = difflib.ndiff(original_lines, modified_lines)\n",
    "    highlighted = []\n",
    "    \n",
    "    for line in diff:\n",
    "        if line.startswith(\"+ \"):  # Added text\n",
    "            highlighted.append(f\"[MODIFIED] {line[2:]}\")\n",
    "        elif line.startswith(\"- \"):  # Removed text\n",
    "            highlighted.append(f\"[REMOVED] {line[2:]}\")\n",
    "        else:\n",
    "            highlighted.append(line[2:])  \n",
    "    \n",
    "    return \"\\n\".join(highlighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a01d4b9f-84cf-4f1f-8db8-ee290e88154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clean_text(perturbed_text):\n",
    "    \"\"\"\n",
    "    Removes [MODIFIED], [REMOVED] tags and explanations, leaving only the modified version.\n",
    "    \"\"\"\n",
    "    # Remove any [MODIFIED] or [REMOVED] markers\n",
    "    clean_text = re.sub(r\"\\[MODIFIED\\]|\\[REMOVED\\]\", \"\", perturbed_text)\n",
    "    \n",
    "    # Remove explanations (assuming they are after a certain marker like \"Explanation:\")\n",
    "    clean_text = re.sub(r\"Explanation:.*\", \"\", clean_text, flags=re.DOTALL)\n",
    "    \n",
    "    # Clean up extra spaces that may remain after removal\n",
    "    clean_text = re.sub(r\"\\n\\s*\\n\", \"\\n\", clean_text).strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "35460d2e-a980-4e0c-9807-1b046f757178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unsupported file: .ipynb_checkpoints\n",
      "Processing CreditcardscomInc_20070810_S-1_EX-10.33_362297_EX-10.33_Affiliate Agreement.pdf...\n",
      "json file: test_benchmark_dataset/ambiguity_legal_contradication_json/perturbed_CreditcardscomInc_20070810_S-1_EX-10.33_362297_EX-10.33_Affiliate Agreement.pdf.json\n",
      "File successfully loaded\n",
      "File modified, saving...\n",
      "________________________________________________________________________\n",
      "Processing CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605784_EX-10.27_Affiliate Agreement.pdf...\n",
      "json file: test_benchmark_dataset/ambiguity_legal_contradication_json/perturbed_CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605784_EX-10.27_Affiliate Agreement.pdf.json\n",
      "File successfully loaded\n",
      "File modified, saving...\n",
      "________________________________________________________________________\n",
      "Processing DigitalCinemaDestinationsCorp_20111220_S-1_EX-10.10_7346719_EX-10.10_Affiliate Agreement.pdf...\n",
      "json file: test_benchmark_dataset/ambiguity_legal_contradication_json/perturbed_DigitalCinemaDestinationsCorp_20111220_S-1_EX-10.10_7346719_EX-10.10_Affiliate Agreement.pdf.json\n",
      "File successfully loaded\n",
      "File modified, saving...\n",
      "________________________________________________________________________\n",
      "Processing LinkPlusCorp_20050802_8-K_EX-10_3240252_EX-10_Affiliate Agreement.pdf...\n",
      "json file: test_benchmark_dataset/ambiguity_legal_contradication_json/perturbed_LinkPlusCorp_20050802_8-K_EX-10_3240252_EX-10_Affiliate Agreement.pdf.json\n",
      "File successfully loaded\n",
      "File modified, saving...\n",
      "________________________________________________________________________\n",
      "Processing SouthernStarEnergyInc_20051202_SB-2A_EX-9_801890_EX-9_Affiliate Agreement.pdf...\n",
      "json file: test_benchmark_dataset/ambiguity_legal_contradication_json/perturbed_SouthernStarEnergyInc_20051202_SB-2A_EX-9_801890_EX-9_Affiliate Agreement.pdf.json\n",
      "File successfully loaded\n",
      "Warning: Could not find section in text: element 5 will pay Affiliate its advertising costs (including Vat, if any, on presentation of a valid VAT invoice) if an end user arrives via the link integrated in Affiliate's Web site at the order page hosted by element 5 for the respective Software Publisher's Product under this Agreement and end user uses the automatic ordering system that carries out the registration and payment processing, so that the Affiliate's link is deemed to be directly causative for the entry of the End User into the agreement with the Software Publisher and End User's payment, proving that all requirements are irrevocably met (\"agreements arising in a qualified manner\").\n",
      "________________________________________________________________________\n",
      "Processing SteelVaultCorp_20081224_10-K_EX-10.16_3074935_EX-10.16_Affiliate Agreement.pdf...\n",
      "json file: test_benchmark_dataset/ambiguity_legal_contradication_json/perturbed_SteelVaultCorp_20081224_10-K_EX-10.16_3074935_EX-10.16_Affiliate Agreement.pdf.json\n",
      "File successfully loaded\n",
      "File modified, saving...\n",
      "________________________________________________________________________\n",
      "Processing TubeMediaCorp_20060310_8-K_EX-10.1_513921_EX-10.1_Affiliate Agreement.pdf...\n",
      "json file: test_benchmark_dataset/ambiguity_legal_contradication_json/perturbed_TubeMediaCorp_20060310_8-K_EX-10.1_513921_EX-10.1_Affiliate Agreement.pdf.json\n",
      "File successfully loaded\n",
      "Warning: Could not find section in text: (c) Affiliate shall retain the right to elect not to transmit any programming on the Service over the broadcast facilities of a Station if Affiliate reasonably believes that such programming is unsatisfactory or unsuitable or contrary to the public interest, or in order to substitute a program which, in Affiliate’s judgment, is of greater local or national importance. Affiliate agrees to notify Network either before or as soon as reasonably practicable after Affiliate exercises such right.\n",
      "________________________________________________________________________\n",
      "Processing UnionDentalHoldingsInc_20050204_8-KA_EX-10_3345577_EX-10_Affiliate Agreement.pdf...\n",
      "json file: test_benchmark_dataset/ambiguity_legal_contradication_json/perturbed_UnionDentalHoldingsInc_20050204_8-KA_EX-10_3345577_EX-10_Affiliate Agreement.pdf.json\n",
      "File successfully loaded\n",
      "File modified, saving...\n",
      "________________________________________________________________________\n",
      "Processing UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf...\n",
      "json file: test_benchmark_dataset/ambiguity_legal_contradication_json/perturbed_UsioInc_20040428_SB-2_EX-10.11_1723988_EX-10.11_Affiliate Agreement 2.pdf.json\n",
      "File successfully loaded\n",
      "File modified, saving...\n",
      "________________________________________________________________________\n",
      "All perturbations saved in test_benchmark_dataset/ambiguity_legal_contradication/\n"
     ]
    }
   ],
   "source": [
    "# Destination directory creation and check\n",
    "os.makedirs(folder_path_json, exist_ok=True)\n",
    "os.makedirs(folder_path_save, exist_ok=True)\n",
    "\n",
    "perturbation_type = \"contradiction\"  # Change to \"ambiguity\", \"omission\", etc.\n",
    "perturbed_legal_docs = apply_perturbations(folder_path_read, folder_path_json, folder_path_save, perturbation_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566b468-b618-4329-99cf-afaeb859f7eb",
   "metadata": {},
   "source": [
    "# End of Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8a861dbc-fca6-4d06-b681-d5fff8defa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOP\n"
     ]
    }
   ],
   "source": [
    "print(\"EOP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
